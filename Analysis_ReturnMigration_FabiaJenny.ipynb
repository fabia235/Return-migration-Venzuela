{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sending GET requests from the API\n",
    "import requests\n",
    "# For saving access tokens and for file management when creating and adding to the dataset\n",
    "import os\n",
    "# For dealing with json responses we receive from the API\n",
    "import json\n",
    "# For displaying the data after\n",
    "import pandas as pd\n",
    "# For parsing the dates received from twitter in readable formats\n",
    "import datetime\n",
    "#To add wait time between requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytz\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import sys\n",
    "import folium\n",
    "from folium.plugins import HeatMap, HeatMapWithTime\n",
    "from scipy.stats import gaussian_kde\n",
    "import datetime as dt\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKEN'] = '  '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auth():\n",
    "    return os.getenv('TOKEN')\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def create_url(keyword, start_date, end_date, max_results = 15):\n",
    "    \n",
    "    search_url = \"https://api.twitter.com/2/tweets/search/all\" #Change to the endpoint you want to collect data from\n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword,\n",
    "                    'start_time': start_date,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': 'geo.place_id,author_id',\n",
    "                    'tweet.fields': 'id,text,author_id,geo,conversation_id,created_at,lang',\n",
    "                    'user.fields': 'id,name,username,created_at,description,public_metrics,location',\n",
    "                    'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs for tweets\n",
    "bearer_token = auth()\n",
    "headers = create_headers(bearer_token)\n",
    "keyword = \"place_country:VE has:geo -is:retweet\"\n",
    "start_list =    [\n",
    "'2022-01-01T00:00:00.000Z'\n",
    "'2022-02-01T00:00:00.000Z',\n",
    "'2022-03-01T00:00:00.000Z',\n",
    "'2022-04-01T00:00:00.000Z',\n",
    "'2022-05-01T00:00:00.000Z',\n",
    "'2022-06-01T00:00:00.000Z',\n",
    "'2022-07-01T00:00:00.000Z',\n",
    "'2022-08-01T00:00:00.000Z',\n",
    "'2022-09-01T00:00:00.000Z',\n",
    "'2022-10-01T00:00:00.000Z',\n",
    "'2022-11-01T00:00:00.000Z',\n",
    "'2022-12-01T00:00:00.000Z']\n",
    "\n",
    "end_list =      [\n",
    "                 \n",
    "                 \n",
    "                '2022-01-31T00:00:00.000Z',\n",
    "                 '2022-02-28T23:59:59.000Z',\n",
    "                 '2022-03-31T23:59:59.000Z',\n",
    "                 '2022-04-30T23:59:59.000Z',\n",
    "                 '2022-05-31T23:59:59.000Z',\n",
    "                 '2022-06-30T23:59:59.000Z',\n",
    "                 '2022-07-31T23:59:59.000Z',\n",
    "                 '2022-08-31T23:59:59.000Z',\n",
    "                 '2022-09-30T23:59:59.000Z',\n",
    "                 '2022-10-31T23:59:59.000Z',\n",
    "                 '2022-11-30T23:59:59.000Z',\n",
    "                 '2022-12-31T23:59:59.000Z']\n",
    "\n",
    "               \n",
    "\n",
    "max_results = 500\n",
    "\n",
    "#Total number of tweets we collected from the loop\n",
    "total_tweets = 0\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(start_list)):\n",
    "    result = []\n",
    "    # Inputs\n",
    "    count = 0 # Counting tweets per time period\n",
    "    flag = True\n",
    "    next_token = None\n",
    "    \n",
    "\n",
    "    while flag:\n",
    "\n",
    "        print(\"-------------------\")\n",
    "        print(\"Token: \", next_token)\n",
    "        url = create_url(keyword, start_list[i],end_list[i], max_results)\n",
    "        json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "        result_count = json_response['meta']['result_count']\n",
    "\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(\"Next Token: \", next_token)\n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                print(\"Start Date: \", start_list[i])\n",
    "                result.append(json_response)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5) \n",
    "            with open(f\"VEN2022{i+10}.json\", \"w\") as f:\n",
    "                json.dump(result, f)  \n",
    "\n",
    "        # If no next token exists\n",
    "        else:\n",
    "            if result_count is not None and result_count > 0:\n",
    "                print(\"-------------------\")\n",
    "                print(\"Start Date: \", start_list[i])\n",
    "                result.append(json_response)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)\n",
    "            with open(f\"VEN2022{i+10}.json\", \"w\") as f:\n",
    "                json.dump(result, f) \n",
    "            #Since this is the final request, turn flag to false to move to the next time period.\n",
    "            flag = False\n",
    "            next_token = None\n",
    "        time.sleep(5)\n",
    "print(\"Total number of results: \", total_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('VEN20220.json', 'r', encoding='utf-8') as file:\n",
    "    Jan22 = json.load(file)\n",
    "with open ('VEN20221.json', 'r', encoding='utf-8') as file:\n",
    "    Feb22 = json.load(file)\n",
    "with open ('VEN20222.json', 'r', encoding='utf-8') as file:\n",
    "    March22 = json.load(file)\n",
    "with open ('VEN20223.json', 'r', encoding='utf-8') as file:\n",
    "    April22 = json.load(file)\n",
    "with open ('VEN20224.json', 'r', encoding='utf-8') as file:\n",
    "    May22 = json.load(file)\n",
    "with open ('VEN20225.json', 'r', encoding='utf-8') as file:\n",
    "    June22 = json.load(file)\n",
    "with open ('VEN20226.json', 'r', encoding='utf-8') as file:\n",
    "    July22 = json.load(file)\n",
    "with open ('VEN20227.json', 'r', encoding='utf-8') as file:\n",
    "    Aug22 = json.load(file)\n",
    "with open ('VEN20228.json', 'r', encoding='utf-8') as file:\n",
    "    Sept22 = json.load(file)\n",
    "with open ('VEN20229.json', 'r', encoding='utf-8') as file:\n",
    "    Oct22 = json.load(file)\n",
    "with open ('VEN202210.json', 'r', encoding='utf-8') as file:\n",
    "    Nov22 = json.load(file)\n",
    "with open ('VEN202211.json', 'r', encoding='utf-8') as file:\n",
    "    Dec22 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tweets from json file\n",
    "# This needs to be done for each month\n",
    "\n",
    "Tweet_list= []\n",
    "problems = []\n",
    "for item in Jan22:\n",
    "    Tweets = []\n",
    "    data = item['data']\n",
    "    for j in data:\n",
    "        \n",
    "        Created_at= j['created_at']\n",
    "        \n",
    "        User_ID = j['author_id']\n",
    "        Tweet_ID = j['id']\n",
    "        \n",
    "        try:\n",
    "            Place_Id = j['geo']['place_id']\n",
    "      \n",
    "        except KeyError as e:\n",
    "            if e.args[0] == 'place_id':\n",
    "                \n",
    "                Place_Id = [j['geo']]\n",
    "            else:\n",
    "                print('appended')\n",
    "                problems.append(j)\n",
    "                Place_Id = None\n",
    "            \n",
    "        Tweet = [User_ID, Created_at, Place_Id, Tweet_ID]\n",
    "        Tweets.append(Tweet)\n",
    "    Tweet_list.extend(Tweets)\n",
    "\n",
    "# Create a DataFrame for each month's tweets\n",
    "Jan22 = pd.DataFrame(Tweet_list)\n",
    "Jan22.rename(columns = {0 : 'User_ID', 1 : 'Created_At', 2 : 'Place_ID', 3: 'Tweet_ID'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dictionary in which all place information corresponding to the tweets will be stored\n",
    "Places_Dict = {}\n",
    "\n",
    "# Extract the place information drom the json file \n",
    "# This needs to be done for each month\n",
    "for item in Jan21:\n",
    "    includes = item['includes']\n",
    "    Place = includes['places']\n",
    "    for i in Place:\n",
    "        place_id = i['id']\n",
    "        full_name = i['full_name']\n",
    "        bbox = i['geo']['bbox']\n",
    "        PlaceDict= {'full_name':full_name, 'bbox':bbox}\n",
    "        if place_id not in Places_Dict:\n",
    "            Places_Dict[place_id] = PlaceDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a big dataframe with all tweets\n",
    "data_2022 = pd.concat([df_Jan22, df_Feb22, df_March22, df_April22, df_May22, df_June22, df_July22, df_Aug22, df_Sept22, df_Oct22, df_Nov22, df_Dec22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "data_2022.to_csv('data_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom the 'Created_At' column to datetime type to create new columns according to year, month and day of the tweeting date\n",
    "data_2022['Created_At'] = pd.to_datetime(data_2022['Created_At'])\n",
    "\n",
    "data_2022['Year']= data_2022['Created_At'].dt.year\n",
    "data_2022['Month']= data_2022['Created_At'].dt.month\n",
    "data_2022['Day']= data_2022['Created_At'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture all users that tweeted at least three times from Venezuela\n",
    "all_users = list(set(data_2022.User_ID.tolist()))\n",
    "IDs_22 = data_2022.User_ID.tolist()\n",
    "All_IDs = IDs_22 \n",
    "\n",
    "Relevant_IDs = []\n",
    "\n",
    "for element in all_users:\n",
    "    if All_IDs.count(element) >= 3:\n",
    "        Relevant_IDs.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the relevant user IDs\n",
    "with open(all_users, 'w') as file:\n",
    "    for item in Relevant_IDs:\n",
    "        file.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all tweets from Colombia for the relevant users\n",
    "bearer_token = auth()\n",
    "headers = create_headers(bearer_token)\n",
    "start =    '2018-01-01T00:00:00.000Z'\n",
    "\n",
    "end =      '2022-12-31T23:59:59.000Z'\n",
    "max_results = 500\n",
    "\n",
    "#Total number of tweets we collected from the loop\n",
    "total_tweets = 0\n",
    "result = []\n",
    "\n",
    "\n",
    "for i in range(0,len(start_list)):\n",
    "    keyword = \"from:{i} has:geo -is:retweet place_country:CO\"\n",
    "    \n",
    "    # Inputs\n",
    "    count = 0 # Counting tweets per time period\n",
    "    flag = True\n",
    "    next_token = None\n",
    "    \n",
    "    # Check if flag is true\n",
    "    while flag:\n",
    "\n",
    "        print(\"-------------------\")\n",
    "        print(\"Token: \", next_token)\n",
    "        url = create_url(keyword, start,end, max_results)\n",
    "        json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "        result_count = json_response['meta']['result_count']\n",
    "\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(\"Next Token: \", next_token)\n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                \n",
    "                result.append(json_response)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5) \n",
    "  \n",
    "\n",
    "        # If no next token exists\n",
    "        else:\n",
    "            if result_count is not None and result_count > 0:\n",
    "                print(\"-------------------\")\n",
    "                \n",
    "                result.append(json_response)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)\n",
    " \n",
    "            #Since this is the final request, turn flag to false to move to the next time period.\n",
    "            flag = False\n",
    "            next_token = None\n",
    "        time.sleep(5)\n",
    "print(\"Total number of results: \", total_tweets)\n",
    "with open(f\"CO_Tweets.json\", \"w\") as f:\n",
    "                    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tweets from the Json file \n",
    "with open ('CO_Tweets.json', 'r', encoding='utf-8') as file:\n",
    "    CO_Tweets = json.load(file)\n",
    "    \n",
    "Tweet_list= []\n",
    "problems = []\n",
    "for item in CO_Tweets:\n",
    "    Tweets = []\n",
    "    data = item['data']\n",
    "    for j in data:\n",
    "        Created_at= j['created_at']\n",
    "        \n",
    "        User_ID = j['author_id']\n",
    "        Tweet_ID = j['id']\n",
    "        \n",
    "        try:\n",
    "            Place_Id = j['geo']['place_id']\n",
    "      \n",
    "        except KeyError as e:\n",
    "            if e.args[0] == 'place_id':\n",
    "                \n",
    "                Place_Id = [j['geo']]\n",
    "            else:\n",
    "                print('appended')\n",
    "                problems.append(j)\n",
    "                Place_Id = None\n",
    "            \n",
    "        Tweet = [User_ID, Created_at, Place_Id, Tweet_ID]\n",
    "        Tweets.append(Tweet)\n",
    "    Tweet_list.extend(Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the tweets to a dataframe\n",
    "df_CO_Tweets = pd.DataFrame(Tweet_list)\n",
    "df_CO_Tweets.rename(columns = {0 : 'User_ID', 1 : 'Created_At', 2 : 'Place_ID', 3: 'Tweet_ID'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new geo information to the exisiting dict of places\n",
    "for item in df_CO_Tweets:\n",
    "    includes = item['includes']\n",
    "    Place = includes['places']\n",
    "    for i in Place:\n",
    "        place_id = i['id']\n",
    "        full_name = i['full_name']\n",
    "        bbox = i['geo']['bbox']\n",
    "        PlaceDict= {'full_name':full_name, 'bbox':bbox}\n",
    "        if place_id not in Places_Dict:\n",
    "            Places_Dict[place_id] = PlaceDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all unique users who have tweeted from Colombia between 2018 and 2022 \n",
    "CO_Users = list(df_CO_Tweets.User_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download tweets from all around the world for the relevant users between 2018 and 2022\n",
    "\n",
    "bearer_token = auth()\n",
    "headers = create_headers(bearer_token)\n",
    "start ='2018-01-01T00:00:00.000Z'\n",
    "end = '2022-12-31T23:59:59.000Z'\n",
    "                 \n",
    "               \n",
    "max_results = 500\n",
    "\n",
    "#Total number of tweets we collected from the loop\n",
    "total_tweets = 0\n",
    "result = []\n",
    "for i in CO_Users:\n",
    "    \n",
    "    keyword = f\"from:{i} has:geo -place_country:CO -place_country:VE\"\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    flag = True\n",
    "    next_token = None\n",
    "    max_count = 10000\n",
    "    # Check if flag is true\n",
    "    while flag:\n",
    "        \n",
    "        if count >=max_count:\n",
    "            break  \n",
    "        print(\"-------------------\")\n",
    "        print('Author_ID', i)\n",
    "        print(\"Token: \", next_token)\n",
    "        url = create_url(keyword, start_list,end_list, max_results)\n",
    "        json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "        result_count = json_response['meta']['result_count']\n",
    "        \n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(\"Next Token: \", next_token)\n",
    "            \n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                \n",
    "                result.append(json_response)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Author_id:\", i)\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                \n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)                \n",
    "        # If no next token exists\n",
    "        else:\n",
    "            if result_count is not None and result_count > 0:\n",
    "                print(\"-------------------\")\n",
    "                \n",
    "                result.append(json_response)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                print('Author_ID', i)\n",
    "                time.sleep(5)\n",
    "            \n",
    "            #Since this is the final request, turn flag to false to move to the next time period.\n",
    "            flag = False\n",
    "            next_token = None\n",
    "        time.sleep(5)\n",
    "print(\"Total number of results: \", total_tweets)\n",
    "with open(\"Tweets_Global.json\", \"w\") as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tweets from the json file\n",
    "with open ('Tweets_Global.json', 'r', encoding='utf-8') as file:\n",
    "    Global_Tweets = json.load(file)\n",
    "    \n",
    "Tweet_list= []\n",
    "problems = []\n",
    "for item in Global_Tweets:\n",
    "    Tweets = []\n",
    "    data = item['data']\n",
    "    for j in data:\n",
    "        Created_at= j['created_at']\n",
    "        \n",
    "        User_ID = j['author_id']\n",
    "        Tweet_ID = j['id']\n",
    "        \n",
    "        try:\n",
    "            Place_Id = j['geo']['place_id']\n",
    "      \n",
    "        except KeyError as e:\n",
    "            if e.args[0] == 'place_id':\n",
    "                \n",
    "                Place_Id = [j['geo']]\n",
    "            else:\n",
    "                print('appended')\n",
    "                problems.append(j)\n",
    "                Place_Id = None\n",
    "            \n",
    "        Tweet = [User_ID, Created_at, Place_Id, Tweet_ID]\n",
    "        Tweets.append(Tweet)\n",
    "    Tweet_list.extend(Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the tweets to a dataframe\n",
    "df_Global_Tweets = pd.DataFrame(Tweet_list)\n",
    "df_Global_Tweets.rename(columns = {0 : 'User_ID', 1 : 'Created_At', 2 : 'Place_ID', 3: 'Tweet_ID'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new geo information to the exisiting dict of places\n",
    "for item in Global_Tweets:\n",
    "    includes = item['includes']\n",
    "    Place = includes['places']\n",
    "    for i in Place:\n",
    "        place_id = i['id']\n",
    "        full_name = i['full_name']\n",
    "        bbox = i['geo']['bbox']\n",
    "        PlaceDict= {'full_name':full_name, 'bbox':bbox}\n",
    "        if place_id not in Places_Dict:\n",
    "            Places_Dict[place_id] = PlaceDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the missing tweets from all Venezuela the world for the relevant users between 2018 and 2022\n",
    "\n",
    "bearer_token = auth()\n",
    "headers = create_headers(bearer_token)\n",
    "start ='2018-01-01T00:00:00.000Z'\n",
    "end = '2021-12-31T23:59:59.000Z'\n",
    "                 \n",
    "               \n",
    "max_results = 500\n",
    "\n",
    "#Total number of tweets we collected from the loop\n",
    "total_tweets = 0\n",
    "result = []\n",
    "for i in CO_Users:\n",
    "    \n",
    "    keyword = f\"from:{i} has:geo place_country:VE\"\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    flag = True\n",
    "    next_token = None\n",
    "    max_count = 10000\n",
    "    # Check if flag is true\n",
    "    while flag:\n",
    "        \n",
    "        if count >=max_count:\n",
    "            break  \n",
    "        print(\"-------------------\")\n",
    "        print('Author_ID', i)\n",
    "        print(\"Token: \", next_token)\n",
    "        url = create_url(keyword, start_list,end_list, max_results)\n",
    "        json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "        result_count = json_response['meta']['result_count']\n",
    "        \n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(\"Next Token: \", next_token)\n",
    "            \n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                \n",
    "                result.append(json_response)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Author_id:\", i)\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                \n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)                \n",
    "        # If no next token exists\n",
    "        else:\n",
    "            if result_count is not None and result_count > 0:\n",
    "                print(\"-------------------\")\n",
    "                \n",
    "                result.append(json_response)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                print('Author_ID', i)\n",
    "                time.sleep(5)\n",
    "            \n",
    "            #Since this is the final request, turn flag to false to move to the next time period.\n",
    "            flag = False\n",
    "            next_token = None\n",
    "        time.sleep(5)\n",
    "print(\"Total number of results: \", total_tweets)\n",
    "with open(\"Tweets_VE_2018_2021.json\", \"w\") as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tweets from the json file\n",
    "with open ('Tweets_VE_2018_2021.json', 'r', encoding='utf-8') as file:\n",
    "    VE_18_21_Tweets_json = json.load(file)\n",
    "    \n",
    "Tweet_list= []\n",
    "problems = []\n",
    "for item in VE_18_21_Tweets_json:\n",
    "    Tweets = []\n",
    "    data = item['data']\n",
    "    for j in data:\n",
    "        Created_at= j['created_at']\n",
    "        \n",
    "        User_ID = j['author_id']\n",
    "        Tweet_ID = j['id']\n",
    "        \n",
    "        try:\n",
    "            Place_Id = j['geo']['place_id']\n",
    "      \n",
    "        except KeyError as e:\n",
    "            if e.args[0] == 'place_id':\n",
    "                \n",
    "                Place_Id = [j['geo']]\n",
    "            else:\n",
    "                print('appended')\n",
    "                problems.append(j)\n",
    "                Place_Id = None\n",
    "            \n",
    "        Tweet = [User_ID, Created_at, Place_Id, Tweet_ID]\n",
    "        Tweets.append(Tweet)\n",
    "    Tweet_list.extend(Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the tweets to a dataframe\n",
    "VE_18_21_Tweets = pd.DataFrame(Tweet_list)\n",
    "VE_18_21_Tweets.rename(columns = {0 : 'User_ID', 1 : 'Created_At', 2 : 'Place_ID', 3: 'Tweet_ID'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new geo information to the exisiting dict of places\n",
    "for item in VE_18_21_Tweets_json:\n",
    "    includes = item['includes']\n",
    "    Place = includes['places']\n",
    "    for i in Place:\n",
    "        place_id = i['id']\n",
    "        full_name = i['full_name']\n",
    "        bbox = i['geo']['bbox']\n",
    "        PlaceDict= {'full_name':full_name, 'bbox':bbox}\n",
    "        if place_id not in Places_Dict:\n",
    "            Places_Dict[place_id] = PlaceDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VE_2022_Tweets = data_2022[data_2022.User_ID.isin(CO_Users)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the following dataframes with tweets:\n",
    "\n",
    "- Tweets from 2022 from VE\n",
    "- Tweets from 2018 - 2021 from VE\n",
    "- Tweets from all around the world from 2018 - 2022\n",
    "- Tweets from CO from 2018 - 2022\n",
    "\n",
    "To each of these dataframes, the geo information needs to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VE_2022_Tweets['geo'] = df_VE_2022_Tweets['Place_ID'].map(Places_Dict)\n",
    "df_VE_2022_Tweets= pd.concat([df_VE_2022_Tweets, df_VE_2022_Tweets[\"geo\"].apply(pd.Series)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VE_18_21_Tweets['geo'] = VE_18_21_Tweets['Place_ID'].map(Places_Dict)\n",
    "VE_18_21_Tweets= pd.concat([VE_18_21_Tweets, VE_18_21_Tweets[\"geo\"].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CO_Tweets['geo'] = df_CO_Tweets['Place_ID'].map(Places_Dict)\n",
    "df_CO_Tweets= pd.concat([df_CO_Tweets, df_CO_Tweets[\"geo\"].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Global_Tweets['geo'] = df_Global_Tweets['Place_ID'].map(Places_Dict)\n",
    "df_Global_Tweets= pd.concat([df_Global_Tweets, df_Global_Tweets[\"geo\"].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all tweets to one df\n",
    "All_tweets = pd.concat[(df_VE_2022_Tweets, df_Global_Tweets, df_CO_Tweets, VE_18_21_Tweets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_tweets = pd.read_csv('All_Tweets_22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Users = list(All_tweets.User_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3422516"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(All_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3669"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(All_Users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_tweets['Created_At'] = pd.to_datetime(All_tweets['Created_At'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bots = []\n",
    "for user in All_Users:\n",
    "    User_df = All_tweets[All_tweets.User_ID == user].copy()\n",
    "    if len(User_df) > 10000:\n",
    "        Bots.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Bots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.352727189109626"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average Tweet Calculation per Month:\n",
    "grouped = All_tweets.groupby(['Year', 'Month', 'Day', 'User_ID']).count()['Tweet_ID']\n",
    "grouped_df = pd.DataFrame(grouped)\n",
    "Mean_Tweets_month = []\n",
    "grouped_df = grouped_df.reset_index()\n",
    "\n",
    "for user in All_Users:\n",
    "    if user not in Bots:\n",
    "\n",
    "        User_df = grouped_df[grouped_df['User_ID'] == user].copy()\n",
    "    \n",
    "      \n",
    "        User_df['date'] = pd.to_datetime(User_df[['Year', 'Month', 'Day']])\n",
    "\n",
    "        User_df.set_index('date', inplace=True)\n",
    "        a=User_df.resample('M')['Tweet_ID'].sum()\n",
    "        new = pd.DataFrame(a)\n",
    "        start_date = '2018-01-01'\n",
    "        end_date = '2022-12-31'\n",
    "        new_index = pd.date_range(start=start_date, end=end_date, freq='M')\n",
    "        new = new.reindex(new_index, fill_value=0)\n",
    "        List = new.Tweet_ID.tolist()\n",
    "       \n",
    "        Average = sum(List) / len(List)\n",
    "        if Average> 5000:\n",
    "            print(user)\n",
    "        Mean_Tweets_month.append(Average)\n",
    "        \n",
    "\n",
    "Mean = sum(Mean_Tweets_month)/len(Mean_Tweets_month)\n",
    "Mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2744598200145555"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average Tweet Calculation per Day:\n",
    "\n",
    "grouped = All_tweets.groupby(['Year', 'Month', 'Day', 'User_ID']).count()['Tweet_ID']\n",
    "grouped_df = pd.DataFrame(grouped)\n",
    "Mean_Tweets_day = []\n",
    "grouped_df = grouped_df.reset_index()\n",
    "\n",
    "for user in All_Users:\n",
    "    if user not in Bots:\n",
    "\n",
    "        User_df = grouped_df[grouped_df['User_ID'] == user].copy()\n",
    "    \n",
    "      \n",
    "        User_df['date'] = pd.to_datetime(User_df[['Year', 'Month', 'Day']])\n",
    "\n",
    "        User_df.set_index('date', inplace=True)\n",
    "        a=User_df.resample('D')['Tweet_ID'].sum()\n",
    "        new = pd.DataFrame(a)\n",
    "        start_date = '2018-01-01'\n",
    "        end_date = '2022-12-31'\n",
    "        new_index = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "        new = new.reindex(new_index, fill_value=0)\n",
    "        List = new.Tweet_ID.tolist()\n",
    "       \n",
    "        Average = sum(List) / len(List)\n",
    "        if Average> 5000:\n",
    "            print(user)\n",
    "        Mean_Tweets_day.append(Average)\n",
    "        \n",
    "\n",
    "Mean = sum(Mean_Tweets_day)/len(Mean_Tweets_day)\n",
    "Mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Mean_Tweets_month\n",
    "\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=20)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Average Tweets')\n",
    "plt.ylabel('Users')\n",
    "plt.title('Average tweets per month per user')\n",
    "\n",
    "# Display the histogram\n",
    "plt.savefig('MeanTweets_perMonth_noBots.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Mean_Tweets_day\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=20)\n",
    "# Add labels and title\n",
    "plt.xlabel('Average Tweets')\n",
    "plt.ylabel('Users')\n",
    "plt.title('Average tweets per day per user')\n",
    "\n",
    "# Display the histogram\n",
    "plt.savefig('MeanTweets_perDay_noBots.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect users which can be classified as Venezuelan residents\n",
    "\n",
    "Bots = []\n",
    "start_t = None\n",
    "Resident_period = 31\n",
    "Initiation = True\n",
    "target_country = 'VE'\n",
    "maximal_inactivity_period = 31\n",
    "max_period_days = 0\n",
    "max_period_seconds = 0\n",
    "All_Results_df = pd.DataFrame(columns=['Row_Index','User', 'Start', 'End', 'Diff', 'Country', 'Status', 'Restart_Reason'])\n",
    "All_Results_df.to_csv('All_Results_df.csv')\n",
    "\n",
    "\n",
    "for user in All_Users:\n",
    "    User_df = All_tweets[All_tweets['User_ID'] == user].copy()\n",
    "\n",
    "    # Exclude users that tweeted more often than 10000 times over the entire period since these might be bots\n",
    "\n",
    "    if len(User_df) > 10000:\n",
    "        Bots.append(user)\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        User_df = User_df.sort_values('Created_At', ascending=True)\n",
    "        User_df = User_df.reset_index()\n",
    "        Result_df = pd.DataFrame(columns=['Row_Index','User', 'Start', 'End', 'Diff', 'Country', 'Status','Restart_reason'])\n",
    "        Initiation = True\n",
    "        max_period_days= 0\n",
    "        max_period_seconds = 0\n",
    "\n",
    "        print(f'Number of tweets: {len(User_df)}')\n",
    "\n",
    "        # Fetch the country and tweet creation date for the first time\n",
    "        for i, row in User_df.iterrows():\n",
    "            if Initiation == True:\n",
    "                start_c = row['Place']\n",
    "                start_t = row['Created_At']\n",
    "                #print(start_t)\n",
    "                Initiation = False\n",
    "                previous_t = start_t\n",
    "                previous_c = start_c\n",
    "                first_row=0\n",
    "            \n",
    "            # Enter the main loop \n",
    "\n",
    "            else: \n",
    "\n",
    "                # Update the country and tweet creation date currently under consideration\n",
    "\n",
    "                actual_t = row['Created_At']\n",
    "                actual_c = row['Place']\n",
    "\n",
    "                first_row +=1\n",
    "\n",
    "                # Check if the current country corresponds to the previous country\n",
    "\n",
    "                if actual_c == previous_c: \n",
    "\n",
    "                    # Cacluate the time elapsed since pervious tweet\n",
    "                    diff_from_previous_tweet = (actual_t - previous_t).days\n",
    "\n",
    "                    # Check that the time since the last tweet does not exceed the maximal inactivity period\n",
    "                    if diff_from_previous_tweet < maximal_inactivity_period:\n",
    "\n",
    "                        # Calculate the time elapsed since the first tweet from the same country\n",
    "                    \n",
    "                        diff_from_start_days = abs((actual_t - start_t).days)\n",
    "                        diff_from_start_seconds = abs((actual_t - start_t).seconds)\n",
    "                \n",
    "                        if  diff_from_start_days>= max_period_days:\n",
    "                            max_period_days = diff_from_start_days\n",
    "                            max_period_seconds = diff_from_start_seconds\n",
    "                        \n",
    "                        \n",
    "                            # Check if last tweet by user\n",
    "\n",
    "                            if i == User_df.index[-1]:\n",
    "                                insert_row = {}\n",
    "\n",
    "                                insert_row['User'] = row['User_ID']\n",
    "                                insert_row['Start'] = start_t\n",
    "                                insert_row['End'] = actual_t\n",
    "                                insert_row['Diff'] = diff_from_start_seconds\n",
    "                                insert_row['Country'] = previous_c\n",
    "                                insert_row['Row_Index'] = i\n",
    "                                insert_row['Restart_reason'] = 'Last_line'\n",
    "\n",
    "                                # Check if user only tweeted once\n",
    "\n",
    "                                if first_row ==1:\n",
    "                                    insert_row['Status'] = 'Only one tweet'\n",
    "\n",
    "                                # Check if user is tweeting from country country\n",
    "                            \n",
    "                                else:\n",
    "                                    if previous_c == target_country:\n",
    "\n",
    "                                        # Check if period from current tweet since first tweet from the target country correponds at least to the residence period\n",
    "\n",
    "                                        if (actual_t-start_t).days >= Resident_period:\n",
    "                                            insert_row['Status']  = 'Valid'\n",
    "\n",
    "                                        # If the residence time is not reached, the user is not considered resident\n",
    "                                        else:\n",
    "                                            insert_row['Status'] = 'In target country, but not resident'\n",
    "                                    else:\n",
    "                                        insert_row['Status'] = 'Not target country'\n",
    "\n",
    "                                # Add information to result df       \n",
    "                                \n",
    "                                Result_df = pd.concat([Result_df, pd.DataFrame([insert_row])]) \n",
    "\n",
    "                        # Go to next tweet and safe information of current tweet as previous tweet     \n",
    "                        previous_t = actual_t\n",
    "                        previous_c = actual_c    \n",
    "\n",
    "                    # If maximum inactivity period is reached         \n",
    "                    else:\n",
    "                        insert_row = {}\n",
    "\n",
    "                        insert_row['User'] = row['User_ID']\n",
    "                        insert_row['Start'] = start_t\n",
    "                        insert_row['End'] = actual_t\n",
    "                        insert_row['Diff'] = diff_from_start_seconds\n",
    "                        insert_row['Country'] = previous_c\n",
    "                        insert_row['Row_Index'] = i\n",
    "                        insert_row['Restart_reason'] = 'Maximum inactivity'\n",
    "\n",
    "                        # Check if just one tweet from country was sent\n",
    "\n",
    "                        if first_row ==1:\n",
    "                                    insert_row['Status'] = 'Only one tweet'\n",
    "                        else:\n",
    "                            # Check if the previous tweet was sent from the target country     \n",
    "                            if previous_c == target_country:\n",
    "                                # Check if previously the residence period was reached\n",
    "                                if (previous_t-start_t).days >= Resident_period:\n",
    "                                    insert_row['Status']  = 'Valid'\n",
    "                                # If residence period is not reached, user is not considered resident in target country\n",
    "                                else:\n",
    "                                    insert_row['Status'] = 'In target country, but not resident'\n",
    "                            \n",
    "                            else:\n",
    "                                insert_row['Status'] = 'Not target country'\n",
    "                       \n",
    "                        Result_df = pd.concat([Result_df, pd.DataFrame([insert_row])])\n",
    "\n",
    "                        # Restart aggregation of time with the current tweet information\n",
    "                        start_c = row['Place']\n",
    "                        start_t = row['Created_At']\n",
    "                        # During the first loop, the start country and start date, are also the previous tweet\n",
    "                        previous_t = start_t\n",
    "                        previous_c = start_c\n",
    "                        # Reset all the variables\n",
    "                        diff_from_start_days = 0\n",
    "                        diff_from_previous_tweet = 0\n",
    "                        diff_from_start_seconds = 0 \n",
    "                        first_row = 0\n",
    "\n",
    "                # If country is changed        \n",
    "                else: \n",
    "                    insert_row = {}\n",
    "\n",
    "                    insert_row['User'] = row['User_ID']\n",
    "                    insert_row['Start'] = start_t\n",
    "                    insert_row['End'] = previous_t\n",
    "                    insert_row['Diff'] = diff_from_start_seconds\n",
    "                    insert_row['Country'] = previous_c\n",
    "                    insert_row['Row_Index'] = i\n",
    "                    insert_row['Restart_reason'] = 'Change of country'\n",
    "                    # Check if just one tweet is considered \n",
    "                    if first_row ==1:\n",
    "                        insert_row['Status'] = 'Only one tweet'\n",
    "\n",
    "                    # Check if the previous tweet was sent from the target country    \n",
    "                    else:\n",
    "                        if previous_c == target_country:\n",
    "                            # Check if previously the residence period was reached\n",
    "\n",
    "                            if (previous_t-start_t).days >= Resident_period:\n",
    "                                insert_row['Status']  = 'Valid'\n",
    "                            # If residence period is not reached, user is not considered resident in target country\n",
    "                            else:\n",
    "                                insert_row['Status'] = 'In target country, but not resident'\n",
    "                        else:\n",
    "                            insert_row['Status'] = 'Not target country'\n",
    "\n",
    "\n",
    "                    Result_df = pd.concat([Result_df, pd.DataFrame([insert_row])])\n",
    "                    start_c = row['Place']\n",
    "                    start_t = row['Created_At']\n",
    "                    previous_t = start_t\n",
    "                    previous_c = start_c\n",
    "                    diff_from_start_days = 0\n",
    "                    diff_from_previous_tweet = 0\n",
    "                    diff_from_start_seconds = 0\n",
    "                    first_row =0\n",
    "        \n",
    "        All_Results_df = pd.concat([All_Results_df, Result_df])\n",
    "        Result_df.to_csv('All_Results_df.csv', mode='a', header=False)\n",
    "        print(f'User processed: {user} with {len(Result_df)}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = pd.read_csv('All_Results_df_1180.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid_Results = Results[Results.Status == 'Valid']\n",
    "Ve_residents = list(Valid_Results.User.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1180"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ve_residents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bots = []\n",
    "start_t = None\n",
    "Resident_period = 90\n",
    "Initiation = True\n",
    "target_country = 'CO'\n",
    "maximal_inactivity_period = 31\n",
    "max_period_days = 0\n",
    "max_period_seconds = 0\n",
    "All_Results_df_OctDec_res = pd.DataFrame(columns=['Row_Index','User', 'Start', 'End', 'Diff', 'Country', 'Status', 'Restart reason', 'Max_Loc'])\n",
    "All_Results_df_OctDec_res.to_csv('All_Results_df_CO_residents_modal_approach.csv')\n",
    "for user in Ve_residents:\n",
    "    User_df = All_tweets[All_tweets['User_ID'] == user].copy()\n",
    "    if len(User_df) > 10000:\n",
    "        Bots.append(user)\n",
    "        continue\n",
    "    else:\n",
    "        User_df = User_df.sort_values('Created_At', ascending=True)\n",
    "        User_df = User_df.reset_index()\n",
    "        Result_df = pd.DataFrame(columns=['Row_Index','User', 'Start', 'End', 'Diff', 'Country', 'Status','Restart_reason', 'Max_Loc'])\n",
    "        Initiation = True\n",
    "        max_period_days= 0\n",
    "        max_period_seconds = 0\n",
    "        \n",
    "\n",
    "      \n",
    "        for i, row in User_df.iterrows():\n",
    "             \n",
    "            if Initiation == True:\n",
    "                start_c = row['Place']\n",
    "                start_t = row['Created_At']\n",
    "                #print(start_t)\n",
    "                start_index = i\n",
    "                Initiation = False\n",
    "                Restart = False\n",
    "                previous_t = start_t\n",
    "                previous_c = start_c\n",
    "                first_row=0\n",
    "                    #at the beginning\n",
    "            \n",
    "            else: #main loop \n",
    "                \n",
    "                    \n",
    "                     \n",
    "                #Restart = False\n",
    "                #index = User_df.index[User_df['Created_At'] == start_t]\n",
    "                #print(start_t)\n",
    "                \n",
    "                actual_t = row['Created_At']\n",
    "                actual_c = row['Place']\n",
    "                first_row +=1\n",
    "                if actual_c == previous_c: \n",
    "                    diff_from_previous_tweet = (actual_t - previous_t).days\n",
    "            \n",
    "                    if diff_from_previous_tweet < maximal_inactivity_period:\n",
    "                        diff_from_start_days = abs((actual_t - start_t).days)\n",
    "                        diff_from_start_seconds = abs((actual_t - start_t).seconds)\n",
    "                \n",
    "                        if  diff_from_start_days>= max_period_days:\n",
    "                            max_period_days = diff_from_start_days\n",
    "                            max_period_seconds = diff_from_start_seconds\n",
    "                        \n",
    "                        \n",
    "                    \n",
    "                            if i == User_df.index[-1]:\n",
    "                                insert_row = {}\n",
    "\n",
    "                                insert_row['User'] = row['User_ID']\n",
    "                                insert_row['Start'] = start_t\n",
    "                                insert_row['End'] = actual_t\n",
    "                                insert_row['Diff'] = diff_from_start_days\n",
    "                                insert_row['Country'] = previous_c\n",
    "                                insert_row['Row_Index'] = i\n",
    "                                insert_row['Restart_reason'] = 'Last_line'\n",
    "                                if first_row ==1:\n",
    "                                    insert_row['Status'] = 'Only one tweet'\n",
    "                                else:\n",
    "                                    if previous_c == target_country:\n",
    "                                        if (actual_t-start_t).days >= Resident_period:\n",
    "                                            insert_row['Status']  = 'Valid'\n",
    "                                            valid_row = {}\n",
    "                                            \n",
    "                                            \n",
    "                                            for ind, row in User_df.iloc[start_index:i].iterrows():\n",
    "                                                Place_ID = row['Place_ID']\n",
    "                                                Full_name = row['full_name']\n",
    "                                                if Place_ID not in valid_row:\n",
    "                                                    valid_row[Place_ID] = {}\n",
    "                                                    valid_row[Place_ID]['Full_name'] =  row['full_name']\n",
    "                                                    valid_row[Place_ID]['Occurence'] = 1\n",
    "                                                    valid_row[Place_ID]['Place_ID'] = Place_ID\n",
    "                                                else:\n",
    "                                                    valid_row[Place_ID]['Occurence'] += 1\n",
    "\n",
    "                                            Max_Duration = max(valid_row.values(), key=lambda x: x['Occurence'])\n",
    "                                            Exact_Loc = Max_Duration\n",
    "                                            insert_row['Max_Loc'] = Exact_Loc\n",
    "\n",
    "                                        else:\n",
    "                                            insert_row['Status'] = 'In target country, but not resident'\n",
    "                                    else:\n",
    "                                        insert_row['Status'] = 'Not target country'\n",
    "                                Result_df = pd.concat([Result_df, pd.DataFrame([insert_row])])      \n",
    "                        previous_t = actual_t\n",
    "                        previous_c = actual_c    \n",
    "                            \n",
    "                    else: # restart, maximum inactivity \n",
    "                        insert_row = {}\n",
    "\n",
    "                        insert_row['User'] = row['User_ID']\n",
    "                        insert_row['Start'] = start_t\n",
    "                        insert_row['End'] = actual_t\n",
    "                        insert_row['Diff'] = diff_from_start_days\n",
    "                        insert_row['Country'] = previous_c\n",
    "                        insert_row['Row_Index'] = i\n",
    "                        insert_row['Restart_reason'] = 'Maximum inactivity'\n",
    "                        if first_row ==8:\n",
    "                                    insert_row['Status'] = 'Only one tweet'\n",
    "                        else:\n",
    "                                \n",
    "                            if previous_c == target_country:\n",
    "                                if (previous_t-start_t).days >= Resident_period:\n",
    "                                    insert_row['Status']  = 'Valid'\n",
    "                                    print('Valid in max inactivity')\n",
    "                                    valid_row = {}\n",
    "                                        \n",
    "                                    Init = True\n",
    "                        \n",
    "                                    for ind, row in User_df.iloc[start_index:i].iterrows():\n",
    "                                        Place_ID = row['Place_ID']\n",
    "                                        Full_name= row['full_name']\n",
    "                                        if Place_ID not in valid_row:\n",
    "                                            valid_row[Place_ID] = {}\n",
    "                                            valid_row[Place_ID]['Full_name'] =  [Full_name]\n",
    "                                            valid_row[Place_ID]['Occurence'] = 1\n",
    "                                            valid_row[Place_ID]['Place_ID'] = Place_ID\n",
    "                                        else:\n",
    "                                            valid_row[Place_ID]['Occurence'] += 1\n",
    "    \n",
    "                                    Max_Duration = max(valid_row.values(), key=lambda x: x['Occurence'])\n",
    "                                    \n",
    "                                                    \n",
    "                                   \n",
    "       \n",
    "                                    Exact_Loc = Max_Duration\n",
    "                                    insert_row['Max_Loc'] = Exact_Loc\n",
    "\n",
    "                                else:\n",
    "                                    insert_row['Status'] = 'In target country, but not resident'\n",
    "                            else:\n",
    "                                insert_row['Status'] = 'Not target country'\n",
    "                       \n",
    "                        Result_df = pd.concat([Result_df, pd.DataFrame([insert_row])])\n",
    "                        start_c = row['Place']\n",
    "                        start_t = row['Created_At']\n",
    "                        start_index = i\n",
    "                        previous_t = start_t\n",
    "                        previous_c = start_c\n",
    "                        diff_from_start_days = 0\n",
    "                        diff_from_previous_tweet = 0\n",
    "                        diff_from_start_seconds = 0 \n",
    "                        first_row = 0\n",
    "                else: #change in country, restart \n",
    "                    insert_row = {}\n",
    "\n",
    "                    insert_row['User'] = row['User_ID']\n",
    "                    insert_row['Start'] = start_t\n",
    "                    insert_row['End'] = previous_t\n",
    "                    insert_row['Diff'] = diff_from_start_days\n",
    "                    insert_row['Country'] = previous_c\n",
    "                    insert_row['Row_Index'] = i\n",
    "                    insert_row['Restart_reason'] = 'Change of country'\n",
    "                    if first_row ==1:\n",
    "                        insert_row['Status'] = 'Only one tweet'\n",
    "                    else:\n",
    "                        if previous_c == target_country:\n",
    "                            if (previous_t-start_t).days >= Resident_period:\n",
    "                                insert_row['Status']  = 'Valid'\n",
    "                                \n",
    "                                valid_row = {}\n",
    "                                \n",
    "                                Init = True\n",
    "                           \n",
    "                                for ind, row in User_df.iloc[start_index:i].iterrows():\n",
    "                                    Place_ID = row['Place_ID']\n",
    "                                    Full_name = row['full_name']\n",
    "                                    if Place_ID not in valid_row:\n",
    "                                        valid_row[Place_ID] = {}\n",
    "                                        valid_row[Place_ID]['Full_name'] =  [Full_name]\n",
    "                                        valid_row[Place_ID]['Occurence'] = 1\n",
    "                                        valid_row[Place_ID]['Place_ID'] = Place_ID\n",
    "                                    else:\n",
    "                                        valid_row[Place_ID]['Occurence'] += 1\n",
    "      \n",
    "                                Max_Duration = max(valid_row.values(), key=lambda x: x['Occurence'])\n",
    "                                Exact_Loc = Max_Duration\n",
    "                                insert_row['Max_Loc'] = Exact_Loc\n",
    "\n",
    "                            else:\n",
    "                                insert_row['Status'] = 'In target country, but not resident'\n",
    "                        else:\n",
    "                            insert_row['Status'] = 'Not target country'\n",
    "                    Result_df = pd.concat([Result_df, pd.DataFrame([insert_row])])\n",
    "                    start_c = row['Place']\n",
    "                    start_t = row['Created_At']\n",
    "                    start_index = i\n",
    "                    previous_t = start_t\n",
    "                    previous_c = start_c\n",
    "                    diff_from_start_days = 0\n",
    "                    diff_from_previous_tweet = 0\n",
    "                    diff_from_start_seconds = 0\n",
    "                    first_row =0\n",
    "        \n",
    "        All_Results_df_OctDec_res = pd.concat([All_Results_df_OctDec_res, Result_df])\n",
    "        Result_df.to_csv('All_Results_df_CO_residents_modal_approach.csv', mode='a', header=False)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modal_results = pd.read_csv('All_Results_df_CO_residents_modal_approach.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modal_results['Start'] = pd.to_datetime(Modal_results['Start'])\n",
    "Modal_results['End'] = pd.to_datetime(Modal_results['End'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modal_results_valid = Modal_results[Modal_results.Status == 'Valid']\n",
    "Modal_results_valid['Start'] = pd.to_datetime(Modal_results_valid['Start'])\n",
    "Modal_results_valid['End'] = pd.to_datetime(Modal_results_valid['End'])\n",
    "CO_residents_modal = list(Modal_results_valid.User.unique())\n",
    "len(CO_residents_modal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to check into which months each residence period falls  \n",
    "\n",
    "def is_within_month(start_date, end_date, year, month):\n",
    "    # Create UTC timezone object\n",
    "    timezone = pytz.timezone('UTC')\n",
    "    # Get current date and time in UTC timezone\n",
    "    \n",
    "    now = dt.datetime.now(timezone)\n",
    "    month_start = dt.datetime(year, month, 1, tzinfo=timezone)\n",
    "    month_end = month_start.replace(day=28) + dt.timedelta(days=4)\n",
    "    month_end = month_end - dt.timedelta(days=month_end.day)\n",
    "    return start_date <= month_end and end_date >= month_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2018_01': 0, '2018_02': 0, '2018_03': 0, '2018_04': 0, '2018_05': 0, '2018_06': 0, '2018_07': 0, '2018_08': 0, '2018_09': 0, '2018_10': 0, '2018_11': 0, '2018_12': 0, '2019_01': 0, '2019_02': 0, '2019_03': 0, '2019_04': 0, '2019_05': 0, '2019_06': 0, '2019_07': 0, '2019_08': 0, '2019_09': 0, '2019_10': 0, '2019_11': 0, '2019_12': 0, '2020_01': 0, '2020_02': 0, '2020_03': 0, '2020_04': 0, '2020_05': 0, '2020_06': 0, '2020_07': 0, '2020_08': 0, '2020_09': 0, '2020_10': 0, '2020_11': 0, '2020_12': 0, '2021_01': 0, '2021_02': 0, '2021_03': 0, '2021_04': 0, '2021_05': 0, '2021_06': 0, '2021_07': 0, '2021_08': 0, '2021_09': 0, '2021_10': 0, '2021_11': 0, '2021_12': 0, '2022_01': 0, '2022_02': 0, '2022_03': 0, '2022_04': 0, '2022_05': 0, '2022_06': 0, '2022_07': 0, '2022_08': 0, '2022_09': 0, '2022_10': 0, '2022_11': 0, '2022_12': 0}\n"
     ]
    }
   ],
   "source": [
    "months_dict = {}\n",
    "\n",
    "# Loop through the years 2018 to 2022 and the months 1 to 12 for each year\n",
    "for year in range(2018, 2023):\n",
    "    for month in range(1, 13):\n",
    "        # Create a key for the month, with leading zeros if necessary (e.g., '2018_01')\n",
    "        key = f\"{year}_{month:02d}\"\n",
    "        # Assign an initial value of None to the key\n",
    "        \n",
    "        months_dict[key] = 0\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(months_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in CO_residents_modal:\n",
    "    User_df = Modal_results_valid[Modal_results_valid['User'] == user].copy()\n",
    "    for i, r in User_df.iterrows():\n",
    "        start = r['Start']\n",
    "        \n",
    "        end = r['End']\n",
    "        for key in months_dict.keys():\n",
    "            # Extract year and month as integers\n",
    "            year_str, month_str = key.split('_')\n",
    "            year = int(year_str)\n",
    "            month = int(month_str)\n",
    "            # Print year and month\n",
    "          \n",
    "            if is_within_month(start, end, year, month):\n",
    "                months_dict[key] += 1\n",
    "                break\n",
    "\n",
    "months_dict_VE = {}\n",
    "\n",
    "# Loop through the years 2018 to 2022 and the months 1 to 12 for each year\n",
    "for year in range(2018, 2023):\n",
    "    for month in range(1, 13):\n",
    "        # Create a key for the month, with leading zeros if necessary (e.g., '2018_01')\n",
    "        key = f\"{year}_{month:02d}\"\n",
    "        # Assign an initial value of None to the key\n",
    "        \n",
    "        months_dict_VE[key] = 0\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(months_dict_VE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for user in CO_residents_modal:\n",
    "    User_df = Valid_Results[Valid_Results['User'] == user].copy()\n",
    "    for i, r in User_df.iterrows():\n",
    "        start = r['Start']\n",
    "        \n",
    "        end = r['End']\n",
    "        for key in months_dict_VE.keys():\n",
    "            # Extract year and month as integers\n",
    "            year_str, month_str = key.split('_')\n",
    "            year = int(year_str)\n",
    "            month = int(month_str)\n",
    "            # Print year and month\n",
    "          \n",
    "            if is_within_month(start, end, year, month):\n",
    "                months_dict_VE[key] += 1\n",
    "                break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame for the first line\n",
    "df_months_VE = pd.DataFrame(months_dict_VE, index=months_dict.keys())\n",
    "df_months_VE = df_months_VE.iloc[[0]]\n",
    "df_months_VE = df_months_VE.T\n",
    "df_months_VE = df_months_VE.reset_index()\n",
    "df_months_VE.rename(columns={'index':'date','2018_01': 'Total' }, inplace=True)\n",
    "\n",
    "# DataFrame for the second line\n",
    "df_months_CO = pd.DataFrame(months_dict, index=months_dict.keys())\n",
    "df_months_CO = df_months_CO.iloc[[0]]\n",
    "df_months_CO = df_months_CO.T\n",
    "df_months_CO = df_months_CO.reset_index()\n",
    "df_months_CO.rename(columns={'index':'date','2018_01': 'Total' }, inplace=True)\n",
    "\n",
    "# Plotting\n",
    "x_values_VE = df_months_VE['date']\n",
    "plt.plot(x_values_VE, df_months_VE['Total'], label='Total migrants residing in Venezuela')\n",
    "\n",
    "x_values_CO = df_months_CO['date']\n",
    "plt.plot(x_values_CO, df_months_CO['Total'], label='Total migrants residing in Colombia')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Total migrants residing in Venezuela and Colombia: Exclusive tweeting model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total')\n",
    "plt.xticks(range(len(x_values_VE))[::3], x_values_VE[::3], rotation=90)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "\n",
    "# Save and display the plot\n",
    "plt.savefig('Combined_Plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2018_01': 0, '2018_02': 0, '2018_03': 0, '2018_04': 0, '2018_05': 0, '2018_06': 0, '2018_07': 0, '2018_08': 0, '2018_09': 0, '2018_10': 0, '2018_11': 0, '2018_12': 0, '2019_01': 0, '2019_02': 0, '2019_03': 0, '2019_04': 0, '2019_05': 0, '2019_06': 0, '2019_07': 0, '2019_08': 0, '2019_09': 0, '2019_10': 0, '2019_11': 0, '2019_12': 0, '2020_01': 0, '2020_02': 0, '2020_03': 0, '2020_04': 0, '2020_05': 0, '2020_06': 0, '2020_07': 0, '2020_08': 0, '2020_09': 0, '2020_10': 0, '2020_11': 0, '2020_12': 0, '2021_01': 0, '2021_02': 0, '2021_03': 0, '2021_04': 0, '2021_05': 0, '2021_06': 0, '2021_07': 0, '2021_08': 0, '2021_09': 0, '2021_10': 0, '2021_11': 0, '2021_12': 0, '2022_01': 0, '2022_02': 0, '2022_03': 0, '2022_04': 0, '2022_05': 0, '2022_06': 0, '2022_07': 0, '2022_08': 0, '2022_09': 0, '2022_10': 0, '2022_11': 0, '2022_12': 0}\n"
     ]
    }
   ],
   "source": [
    "months_dict = {}\n",
    "\n",
    "# Loop through the years 2018 to 2022 and the months 1 to 12 for each year\n",
    "for year in range(2018, 2023):\n",
    "    for month in range(1, 13):\n",
    "        # Create a key for the month, with leading zeros if necessary (e.g., '2018_01')\n",
    "        key = f\"{year}_{month:02d}\"\n",
    "        # Assign an initial value of None to the key\n",
    "        months_dict[key] = 0\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(months_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Months_Dicts = {}\n",
    "for user in CO_residents_modal:\n",
    "    User_df = Modal_results_valid[Modal_results_valid['User'] == user].copy()\n",
    "    for i, r in User_df.iterrows():\n",
    "        start = r['Start']\n",
    "        end = r['End']\n",
    "        Place= r['Max_Loc']\n",
    "    \n",
    "        Place = Place.split(\"'\")\n",
    "        Place_name = Place[3]\n",
    "        Place_ID = Place[9]\n",
    "        if Place_name not in Months_Dicts:\n",
    "            Months_Dicts[Place_name] = {}\n",
    "            for year in range(2018, 2023):\n",
    "                for month in range(1, 13):\n",
    "        # Create a key for the month, with leading zeros if necessary (e.g., '2018_01')\n",
    "                    key = f\"{year}_{month:02d}\"\n",
    "        # Assign an initial value of None to the key\n",
    "                    Months_Dicts[Place_name][key] = 0\n",
    "\n",
    "\n",
    "        for key in Months_Dicts[Place_name].keys():\n",
    "            # Extract year and month as integers\n",
    "            year_str, month_str = key.split('_')\n",
    "            year = int(year_str)\n",
    "            month = int(month_str)\n",
    "            # Print year and month\n",
    "        \n",
    "            if is_within_month(start, end, year, month):\n",
    "                Months_Dicts[Place_name][key] += 1\n",
    "                break\n",
    "\n",
    "df_months = pd.DataFrame(Months_Dicts)\n",
    "\n",
    "\n",
    "new_df = df_months\n",
    "ax = new_df.plot.line()\n",
    "\n",
    "# Move the legend to the right side\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_title('Migrants residing in Colombian cities:\\nExclusive tweeting model')\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and add a 'Total' row which sums up the migrants in CO per month\n",
    "\n",
    "Months_df_exclusive = pd.DataFrame(Months_Dicts)\n",
    "Months_df_exclusive = Months_df_exclusive.T\n",
    "Months_df_exclusive.loc['Total'] = Months_df_exclusive.sum(axis=0)\n",
    "\n",
    "Months_df_exclusive.to_csv('Months_df_exclusiveApproach_modal.csv')\n",
    "\n",
    "# Select time periods to analyze: Inluding recurrent\n",
    "\n",
    "months_df_modal_22_exclusive = Months_df_exclusive.drop(columns=Months_df_exclusive.columns[:48], axis=1)\n",
    "months_df_feb_22_exclusive= months_df_modal_22_exclusive[['2022_02']]\n",
    "Jan_to_March_df_22_exclusive = Months_df_exclusive.iloc[:, 48:51]\n",
    "\n",
    "# Add column with average value per city over the time period selected: Including recurrent\n",
    "\n",
    "Jan_to_March_df_22_exclusive['Mean'] =Jan_to_March_df_22_exclusive.mean(axis=1)\n",
    "months_df_modal_22_exclusive['Mean'] =months_df_modal_22_exclusive.mean(axis=1)\n",
    "months_df_feb_22_exclusive['Mean'] =months_df_feb_22_exclusive.mean(axis=1)\n",
    "\n",
    "\n",
    "# Sort values: Including recurrent\n",
    "\n",
    "Cities_top_22_exclusive = months_df_modal_22_exclusive.sort_values('Mean', ascending=False).head(10)\n",
    "Cities_top_feb_exclusive = months_df_feb_22_exclusive.sort_values('Mean', ascending=False).head(10)\n",
    "Cities_top_Jan_to_March_exclusive = Jan_to_March_df_22_exclusive.sort_values('Mean', ascending=False).head(20)\n",
    "\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "Result_df_city_migrants_upscaled_modal_feb_exclusive = pd.DataFrame(2477588/Cities_top_feb_exclusive.at['Total', 'Mean'] * Cities_top_feb_exclusive['Mean'])\n",
    "\n",
    "Result_df_city_migrants_upscaled_modal_JanMarch_exclusive = pd.DataFrame(2477588/Cities_top_Jan_to_March_exclusive.at['Total', 'Mean'] * Cities_top_Jan_to_March_exclusive['Mean'])\n",
    "\n",
    "Result_df_city_migrants_upscaled_modal_22_exclusive = pd.DataFrame(2477588/Cities_top_22_exclusive.at['Total', 'Mean'] * Cities_top_22_exclusive['Mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_Bogota_22 = 495236\n",
    "official_Medellin_22 = 190854\n",
    "official_Cucuta_22 = 167678\n",
    "official_Candelaria_22 = 121837\n",
    "official_Bucaramanga_22 = 52128\n",
    "official_Barranquilla_22 = 112895\n",
    "official_Cartagena_22 = 70201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratio_JanMarch_Bogota_exclusive = official_Bogota_22/7.33\n",
    "Ratio_JanMarch_Medellin_exclusive = official_Medellin_22/1.33\n",
    "Ratio_JanMarch_Cucuta_exclusive= official_Cucuta_22/1\n",
    "Ratio_JanMarch_Candelaria_exclusive = official_Candelaria_22/0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabia\\AppData\\Local\\Temp\\ipykernel_31596\\1640247279.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Valid_Results['Start'] = pd.to_datetime(Valid_Results['Start'])\n",
      "C:\\Users\\fabia\\AppData\\Local\\Temp\\ipykernel_31596\\1640247279.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Valid_Results['End'] = pd.to_datetime(Valid_Results['End'])\n"
     ]
    }
   ],
   "source": [
    "Valid_Results['Start'] = pd.to_datetime(Valid_Results['Start'])\n",
    "Valid_Results['End'] = pd.to_datetime(Valid_Results['End'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_exclusive = []\n",
    "Ratios_exclusive = []\n",
    "\n",
    "for user in CO_residents_modal:\n",
    "    User_df_VE = Valid_Results[Valid_Results.User == user]\n",
    "    User_df_CO = Modal_results_valid[Modal_results_valid.User == user]\n",
    "\n",
    "    \n",
    "    User_df_VE.sort_values('Start', ascending = True, inplace = True)\n",
    "    User_df_CO.sort_values('Start', ascending = True, inplace = True)\n",
    "    periods_VE = pd.Timedelta(0)\n",
    "    periods_CO = pd.Timedelta(0)\n",
    "    for i,r in User_df_VE.iterrows():\n",
    "        if r['Start'] > User_df_CO.iloc[0]['Start']:\n",
    "            period = r['End'] - r['Start']\n",
    "            periods_VE += period\n",
    "    for i, r in User_df_CO.iterrows():\n",
    "        period = r['End'] - r['Start']\n",
    "        periods_CO += period\n",
    "    print(periods_CO)\n",
    "    print(periods_VE)\n",
    "    Total = periods_CO + periods_VE\n",
    "    Ratio = periods_CO/Total\n",
    "    Ratios_exclusive.append(Ratio)\n",
    "    if Ratio < 0.5:\n",
    "        recurrent_exclusive.append(user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recurrent_exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = Ratios_exclusive\n",
    "\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=20)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Ratio')\n",
    "plt.ylabel('Users')\n",
    "plt.title('Distribution of ratios: Exclusive tweeting model')\n",
    "\n",
    "plt.savefig('Ratios_ExclusiveTweeting_Modal.png')\n",
    "# Display the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results['Start'] = pd.to_datetime(Results['Start'])\n",
    "Results['End'] = pd.to_datetime(Results['End'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Returned_exclusive= []\n",
    "Not_Returned_exclusive=[]\n",
    "\n",
    "for i in CO_residents_modal:\n",
    "    if i not in recurrent_exclusive:\n",
    "        VE_df = Results[Results['User'] == i].copy()\n",
    "        CO_df = Modal_results[Modal_results['User']== i].copy()\n",
    "        Valid_VE = VE_df[VE_df.Status == 'Valid']\n",
    "        Valid_VE.sort_values('User', ascending=True)\n",
    "        Valid_CO = CO_df[CO_df.Status == 'Valid']\n",
    "        Valid_CO.sort_values('Start', ascending = True)\n",
    "        last_VE = Valid_VE.iloc[-1]\n",
    "        last_CO = Valid_CO.iloc[-1]\n",
    "        if last_VE['Start'] > last_CO['End']:\n",
    "      \n",
    "            Returned_exclusive.append(i)\n",
    "        else:\n",
    "         \n",
    "            Not_Returned_exclusive.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(Returned_exclusive))\n",
    "print(len(Not_Returned_exclusive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "Most_Common = {}\n",
    "Last_city = {}\n",
    "Last_city_22={}\n",
    "\n",
    "for i in CO_residents_modal:\n",
    "    User_df = Modal_results[Modal_results['User'] == i].copy()\n",
    "    Frame = User_df[User_df['Status'] == 'Valid']\n",
    "    for index, row in Frame.iterrows():\n",
    "        Place = row['Max_Loc']\n",
    "        Place = Place.split(\"'\")\n",
    "        Place_name = Place[3]\n",
    "        Place_ID = Place[9]\n",
    "        if Place_name in Most_Common:\n",
    "            Most_Common[Place_name]['Total'] += 1\n",
    "        else:\n",
    "            Most_Common[Place_name]= {}\n",
    "            Most_Common[Place_name]['Returned'] = 0\n",
    "            Most_Common[Place_name]['Not_Returned'] = 0\n",
    "            Most_Common[Place_name]['Recurrent'] = 0\n",
    "            Most_Common[Place_name]['Total'] = 1\n",
    "            Most_Common[Place_name]['ID'] = Place_ID\n",
    "        if i in Returned_exclusive:\n",
    "            Most_Common[Place_name]['Returned'] += 1\n",
    "        elif i in Not_Returned_exclusive:\n",
    "            Most_Common[Place_name]['Not_Returned'] += 1\n",
    "        else:\n",
    "            Most_Common[Place_name]['Recurrent'] += 1\n",
    "    Last_Valid = Frame.iloc[-1]\n",
    "    Last_Place = Last_Valid['Max_Loc']\n",
    "      \n",
    "    Last_Place = Last_Place.split(\"'\")\n",
    "    Last_Place_name = Last_Place[3]\n",
    "    Last_Place_ID = Last_Place[9]\n",
    "    if Last_Place_name in Last_city:\n",
    "        Last_city[Last_Place_name]['Total'] +=1\n",
    "    else:\n",
    "        Last_city[Last_Place_name] = {}\n",
    "        Last_city[Last_Place_name]['Total'] =1\n",
    "        Last_city[Last_Place_name]['Returned'] = 0\n",
    "        Last_city[Last_Place_name]['Not_Returned'] = 0\n",
    "        Last_city[Last_Place_name]['Recurrent'] = 0\n",
    "       \n",
    "        Last_city[Last_Place_name]['ID'] = Last_Place_ID\n",
    "    if i in Returned_exclusive:\n",
    "        Last_city[Last_Place_name]['Returned']+= 1\n",
    "    if i in Not_Returned_exclusive:\n",
    "        Last_city[Last_Place_name]['Not_Returned']+= 1\n",
    "    if i in recurrent_exclusive:\n",
    "        Last_city[Last_Place_name]['Recurrent'] +=1\n",
    "\n",
    "\n",
    "    if Last_Valid['End'].year == 2022:\n",
    "        if Last_Place_name in Last_city_22:\n",
    "            Last_city_22[Last_Place_name]['Total'] +=1\n",
    "        else:\n",
    "            Last_city_22[Last_Place_name] = {}\n",
    "            Last_city_22[Last_Place_name]['Total'] =1\n",
    "            Last_city_22[Last_Place_name]['Returned'] = 0\n",
    "            Last_city_22[Last_Place_name]['Not_Returned'] = 0\n",
    "            Last_city_22[Last_Place_name]['Recurrent'] = 0\n",
    "        \n",
    "            Last_city_22[Last_Place_name]['ID'] = Last_Place_ID\n",
    "        if i in Returned_exclusive:\n",
    "            Last_city_22[Last_Place_name]['Returned']+= 1\n",
    "        if i in Not_Returned_exclusive:\n",
    "            Last_city_22[Last_Place_name]['Not_Returned']+= 1\n",
    "        if i in recurrent_exclusive:\n",
    "            Last_city_22[Last_Place_name]['Recurrent'] +=1\n",
    "            \n",
    "\n",
    "Most_Common_modal = pd.DataFrame(Most_Common)\n",
    "Most_Common_modal = Most_Common_modal.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "Last_city_df_modal = pd.DataFrame(Last_city).T.sort_values('Total', ascending=False)\n",
    "Last_city_22_df_modal = pd.DataFrame(Last_city_22).T.sort_values('Total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Last_city_22_df_modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Most_Common_modal = Most_Common_modal.sort_values('Total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Most_Common_modal.head(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratio = []\n",
    "for i,r in Most_Common_modal.iterrows():\n",
    "    try:\n",
    "        Total = (r['Not_Returned']+r['Returned'])\n",
    "        Rat = (r['Not_Returned']/Total)*100\n",
    "    except:\n",
    "        Rat = None\n",
    "    Ratio.append(Rat)\n",
    "\n",
    "Most_Common_modal['Ratio'] = Ratio\n",
    "Most_Common_modal.sort_values('Total', ascending=False, inplace=True)\n",
    "Top = Most_Common_modal.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratio = []\n",
    "for i,r in Last_city_22_df_modal.iterrows():\n",
    "    try:\n",
    "     \n",
    "        Rat = (r['Returned']/r['Not_Returned'])\n",
    "    except:\n",
    "        Rat = 'All returned'\n",
    "    Ratio.append(Rat)\n",
    "\n",
    "Last_city_22_df_modal['Ratio'] = Ratio\n",
    "Last_city_22_df_modal.sort_values('Total', ascending=False, inplace=True)\n",
    "Top = Last_city_22_df_modal.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Last_city_22_df_modal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modal Approach**: *Sliding window*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modal approach with sliding window\n",
    "\n",
    "#Assign each other user a country for each month by using a sliding window of size 3 months \n",
    "#meaning that the middle month of the window gets assigned the country from which most tweets were sent during the window\n",
    "\n",
    "def get_last_day_of_month(input_date):\n",
    "    #input_date needs to be datetime\n",
    "    same_day_next_month = input_date + relativedelta(months=+1)\n",
    "    first_day_next_month = same_day_next_month.replace(day=1)\n",
    "    last_day_current_month = first_day_next_month - timedelta(days=1)\n",
    "    return last_day_current_month\n",
    "\n",
    "\n",
    "df = All_tweets\n",
    "df.rename(columns={'User_ID': 'user', 'Place': 'country', 'Created_At': 'date'}, inplace=True)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['user'] = [str(i) for i in df['user']]\n",
    "all_users = list(df['user'].unique())\n",
    "\n",
    "start_date =  datetime.strptime('01-2018', '%m-%Y')\n",
    "end_date = get_last_day_of_month(datetime.strptime('12-2022', '%m-%Y')) \n",
    "start_date = pd.Timestamp(start_date, tz='UTC')\n",
    "end_date = pd.Timestamp(end_date, tz='UTC')\n",
    "current_date = start_date\n",
    "# 1 month aroung selected month to define window size (3 month)\n",
    "time_delta_for_window = 1  \n",
    "start_date_str = start_date.strftime('%m%Y')\n",
    "\n",
    "tweets_by_country_by_day_dict = {'user':'user0','country':'other', start_date_str:1}\n",
    "df_tweets_by_country_by_day = pd.DataFrame.from_dict(tweets_by_country_by_day_dict,orient='index').reset_index().T\n",
    "\n",
    "#Last_day_of_month to check if correct date has been calculated\n",
    "\n",
    "while (last_day_of_month:=get_last_day_of_month(current_date)) <= end_date : \n",
    "    # The start day of the window needs to be first day of month \n",
    "    start_day_of_window =  current_date - relativedelta(months=+time_delta_for_window) \n",
    "    #Window should not be beyond start_date/end_date:\n",
    "    if start_day_of_window < start_date:\n",
    "        start_day_of_window = start_date\n",
    "\n",
    "    #The end day of the window needs to be last day of month\n",
    "    end_day_of_window =  get_last_day_of_month(current_date + relativedelta(months=+time_delta_for_window)) \n",
    "    if end_day_of_window > end_date: \n",
    "        end_day_of_window = end_date\n",
    "    #Select tweets in window\n",
    "    df_tweets_within_window = df[(df['date'] >= start_day_of_window) & (df['date'] <= end_day_of_window)].copy()\n",
    "    \n",
    "\n",
    "    #Restrict countries: only VE, CO and 'other':\n",
    "    df_tweets_within_window['country'] =  df_tweets_within_window\\\n",
    "        .apply(lambda x: 'other' if (x['country']!='VE')and((x['country']!='CO') ) \\\n",
    "                            else x['country'], axis=1)\n",
    "    \n",
    "    #Count the number of tweets by user, by country within window\n",
    "    df_nr_of_tweets_by_user_country_in_window = df_tweets_within_window\\\n",
    "        .groupby(['user', 'country'], as_index=False).size()\n",
    "    \n",
    "    #select for each user the country with the most tweets\n",
    "    df_country_by_user_with_max_tweets_in_window=df_nr_of_tweets_by_user_country_in_window.loc[df_nr_of_tweets_by_user_country_in_window\\\n",
    "            .groupby([\"user\"])[\"size\"].idxmax().values]\n",
    "\n",
    "    #Drop size column:\n",
    "    df_country_by_user_with_max_tweets_in_window.drop('size', axis=1, inplace=True)  \n",
    "        \n",
    "    #Add column with selected day and set value to 1\n",
    "    current_date_str = current_date.strftime('%m%Y')\n",
    "    df_country_by_user_with_max_tweets_in_window[current_date_str] = 1\n",
    "\n",
    "    print(\"Now processing:\",current_date_str)\n",
    "\n",
    "    #Add rows with other countries but value = 0\n",
    "    df_to_dict = df_country_by_user_with_max_tweets_in_window.to_dict('records')\n",
    "  \n",
    "\n",
    "    for row in df_to_dict:\n",
    " \n",
    "        if row['country']=='VE':\n",
    "            df_country_by_user_with_max_tweets_in_window=\\\n",
    "            pd.concat([df_country_by_user_with_max_tweets_in_window,\\\n",
    "                    pd.DataFrame([{'user':row['user'],'country':'CO', current_date_str:0}])])\n",
    "            df_country_by_user_with_max_tweets_in_window=\\\n",
    "            pd.concat([df_country_by_user_with_max_tweets_in_window,\\\n",
    "                    pd.DataFrame([{'user':row['user'],'country':'other', current_date_str:0}])],ignore_index=True)\n",
    "        elif row['country']=='CO':\n",
    "            df_country_by_user_with_max_tweets_in_window=\\\n",
    "            pd.concat([df_country_by_user_with_max_tweets_in_window,\\\n",
    "                    pd.DataFrame([{'user':row['user'],'country':'VE',current_date_str:0}])],ignore_index=True)\n",
    "            df_country_by_user_with_max_tweets_in_window=\\\n",
    "            pd.concat([df_country_by_user_with_max_tweets_in_window,\\\n",
    "                    pd.DataFrame([{'user':row['user'],'country':'other',current_date_str:0}])],ignore_index=True)\n",
    "        elif row['country']=='other':\n",
    "            df_country_by_user_with_max_tweets_in_window=\\\n",
    "            pd.concat([df_country_by_user_with_max_tweets_in_window,\\\n",
    "                    pd.DataFrame([{'user':row['user'],'country':'VE',current_date_str:0}])],ignore_index=True)\n",
    "            df_country_by_user_with_max_tweets_in_window=\\\n",
    "            pd.concat([df_country_by_user_with_max_tweets_in_window,\\\n",
    "                    pd.DataFrame([{'user':row['user'],'country':'CO',current_date_str:0}])],ignore_index=True)\n",
    "        else:\n",
    "            print(\"ERROR: unexpected country\",row)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        #Add all other users not in window to df with value 0 for all countries VE,CO,'other'\n",
    "    users_in_window = list(df_tweets_within_window['user'].unique())\n",
    "\n",
    "    users_not_in_window = [u for u in all_users if u not in users_in_window]\n",
    "    users_not_in_window_dict = {}\n",
    "    for u in users_not_in_window:\n",
    "        \n",
    "        df_country_by_user_with_max_tweets_in_window=\\\n",
    "        pd.concat([df_country_by_user_with_max_tweets_in_window,\\\n",
    "                pd.DataFrame([{'user':u,'country':'VE',current_date_str:0}])],ignore_index=True)\n",
    "        df_country_by_user_with_max_tweets_in_window=\\\n",
    "        pd.concat([df_country_by_user_with_max_tweets_in_window,\\\n",
    "                pd.DataFrame([{'user':u,'country':'CO',current_date_str:0}])],ignore_index=True)\n",
    "        df_country_by_user_with_max_tweets_in_window=\\\n",
    "        pd.concat([df_country_by_user_with_max_tweets_in_window,\\\n",
    "                pd.DataFrame([{'user':u,'country':'other', current_date_str:0}])],ignore_index=True)\n",
    "\n",
    "    df_result = df_country_by_user_with_max_tweets_in_window \n",
    "    \n",
    "    df_result[current_date_str]= df_result[current_date_str].astype(str) \n",
    "    \n",
    "    #In the first loop, df_overall_result is equal df_result\n",
    "    if current_date == start_date:\n",
    "        df_overall_result = df_result.copy()\n",
    "    else:\n",
    " \n",
    "        df_overall_result = pd.merge(df_overall_result,df_result,on=['user','country'])\n",
    "        \n",
    "\n",
    "    #Remains first day of month but of following month\n",
    "    current_date += relativedelta(months=+1) \n",
    "\n",
    "df_overall_result.to_csv('new_overall_result.csv')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all residents, meaning users who tweeted most frequently from the same country over a three month period\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "debug_mode = False\n",
    "limit_data = False #restrict the processing to 200 users: works only if debug_mode == False\n",
    "short_cut = True # last two month always 'in_transit'\n",
    "\n",
    "if debug_mode:\n",
    "    print(\"INFO: debug mode is activated. Only selected user will be processed. \")\n",
    "if limit_data:\n",
    "    print(\"INFO: limited output data: only 200 users will be processed. \")\n",
    "if short_cut:\n",
    "    print(\"INFO: short cut: last two month will be set to 'in_transit'\")\n",
    "path = \"C:\\\\Users\\\\fabia\\\\OneDrive\\\\\"\n",
    "inputfile = 'new_overall_result_trial.csv'\n",
    "\n",
    "\n",
    "outputfile = 'resident_user_by_country_by_month_in_cols_month.csv' #if user is not resident, he will be assigned to 'in_transit' country\n",
    "filepath = path + '\\\\'+inputfile\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['user'] = [str(i) for i in df['user']]\n",
    "df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "\n",
    "user_residence_periods_dict = {} \n",
    "\n",
    "\n",
    "\n",
    "list_of_cols = df.columns.to_list() #first col: user, second col: country, third and following cols: month\n",
    "nr_of_month = len(list_of_cols)- 2 #nr of month is all columns excluding user and country\n",
    "empty_in_transit_dict = {}\n",
    "empty_no_data_dict = {}\n",
    "\n",
    "if short_cut:\n",
    "    #### SHORTCUT: initialize to 0, but only up to col n-2 und n-1, above everything is 'in_transit'\n",
    "    for i in range(nr_of_month-2):\n",
    "        empty_in_transit_dict.update({list_of_cols[i+2]:0})\n",
    "        empty_no_data_dict.update({list_of_cols[i+2]:0})\n",
    "\n",
    "    #### SHORTCUT: put everything in col n-2 und n-1 to 'in_transit' \n",
    "    for i in range(nr_of_month-2,nr_of_month):\n",
    "        empty_in_transit_dict.update({list_of_cols[i+2]:1})\n",
    "        empty_no_data_dict.update({list_of_cols[i+2]:0})\n",
    "else:\n",
    "    for i in range(nr_of_month):\n",
    "        empty_in_transit_dict.update({list_of_cols[i+2]:0})\n",
    "        empty_no_data_dict.update({list_of_cols[i+2]:0})\n",
    "        \n",
    "\n",
    "all_users = df['user'].unique()\n",
    "resident_country_list = []\n",
    "\n",
    "counter = 0\n",
    "for u in all_users:\n",
    "    ##### LIMIT OUTPUT DATA ##############\n",
    "    if not debug_mode:\n",
    "        if limit_data:\n",
    "            counter += 1\n",
    "            if counter >200:\n",
    "                break\n",
    "    ##### END OF LIMIT OUTPUT DATA  ##############\n",
    "\n",
    "    #to track number of residence countries and length of resident periods:\n",
    "    first_residence_country_found = False\n",
    "    start_period = None\n",
    "    duration = None\n",
    "\n",
    "\n",
    "    #select one user with all his countries:\n",
    "    df_user = df[df['user']== u].copy()\n",
    "    df_user_list_of_dict = df_user.to_dict('records')\n",
    "\n",
    "\n",
    "    ##### DEBUG ##############\n",
    "    if debug_mode:\n",
    "        if u != '100101191': ###JUST TO SELECT ONE USER FOR TESTING/DEBUGGING \n",
    "\n",
    "                continue\n",
    "        else:\n",
    "            df1 = pd.DataFrame(df_user_list_of_dict)\n",
    "            df1.to_csv(\"check_user.csv\")\n",
    "    ##### END OF DEBUG ##############\n",
    "\n",
    "    #### SHORTCUT: put everything in col n-2 und n-1 to 'in_transit', therefore set all countries in n-2, n-1 to 0' \n",
    "    if short_cut:\n",
    "        for i in df_user_list_of_dict: #set all real countrys to 0\n",
    "                i[list_of_cols[-2]] = 0\n",
    "                i[list_of_cols[-1]] = 0\n",
    "\n",
    "    print(u)\n",
    "    col_pointer = 2 #points to the first month col in a triple of cols\n",
    "\n",
    "    #initialize col names:\n",
    "\n",
    "\n",
    "\n",
    "    in_transit_dict = {'user':u,'country':'in_transit'}\n",
    "    in_transit_dict.update(empty_in_transit_dict)\n",
    "    no_data_dict = {'user': u, 'country': 'no data'}\n",
    "    no_data_dict.update(empty_no_data_dict)\n",
    "\n",
    "    df_user_list_of_dict.append(in_transit_dict)\n",
    "    df_user_list_of_dict.append(no_data_dict)\n",
    "\n",
    "    sliding_window_nr_of_cols = 3\n",
    "    first_month = 2 # position of col for first month \n",
    "    nr_of_consecutive_cols_to_find = sliding_window_nr_of_cols #nr_of_consecutive_cols_to_find changes dynamically but starts with sliding window size\n",
    "\n",
    "    while col_pointer+sliding_window_nr_of_cols <= nr_of_month +first_month : # 2 is offset for first_columns\n",
    "        col_list = list_of_cols[col_pointer:col_pointer+nr_of_consecutive_cols_to_find]\n",
    "        ##### DEBUG ##############\n",
    "        # if debug_mode:\n",
    "        #     if col_list[0] == '102018':\n",
    "        #         print('breakpoint')\n",
    "        ##### END OF DEBUG ##############\n",
    "        \n",
    "        #len_of_col_list three consecutives cols starting from pointer\n",
    "\n",
    "        df_user_window = df_user[['country']+col_list]\n",
    "\n",
    "        res_dict = df_user_window[df_user_window[col_list].sum(axis=1)==nr_of_consecutive_cols_to_find].to_dict('records') # e.g. three consecutive cols needs to be 3 to be residents       \n",
    "        \n",
    "        if len(res_dict)>0: # new potential resident country has been found, no_data is False otherwise res_dict would be 0 \n",
    "            # more precisely: in selected col_list, there is one country with nr_of_consecutive_cols_to_find,\n",
    "            # if step = 1 it could still be in_transit \n",
    "            # remark: if len(col_list) == 1, this condition is always true except if no_data\n",
    "            new_resident_country = res_dict[0]['country']\n",
    "            if nr_of_consecutive_cols_to_find < sliding_window_nr_of_cols: # it true it is 1-step only\n",
    "                if not (new_resident_country == resident_country):  #it true it's change of country and 1  step\n",
    "                    # if true the new country does not equal existing resident country and is a change in country\n",
    "                    # because it was only 1 step, it can be checked if the new_resident country is again a new real resident country,\n",
    "                    # this check requires to look at all cols in the sliding_window_nr_of_cols\n",
    "                    # if this check fails, the new resident country will be in transit, no_data is not possible\n",
    "                    col_list = list_of_cols[col_pointer:col_pointer+sliding_window_nr_of_cols] #check all columns in sliding_window_nr_of_cols\n",
    "                    df_user_window = df_user[['country']+col_list]\n",
    "\n",
    "\n",
    "                    res_dict = df_user_window[df_user_window[col_list].sum(axis=1)==sliding_window_nr_of_cols].to_dict('records') # e.g. three consecutive cols needs to be 3 to be residents       \n",
    "                    if len(res_dict)>0: #if true a new resident country has been found\n",
    "                        #track resident periods per users:\n",
    "                        if not first_residence_country_found: #this is the first residence country\n",
    "                            first_residence_country_found = True\n",
    "                            start_period = list_of_cols[col_pointer]\n",
    "                            duration = col_pointer\n",
    "                        else: #store previous residence country\n",
    "                            resident_country_list.extend([{'user':u,'residence_country':resident_country,'start_period':start_period,'duration':col_pointer - duration}])\n",
    "                            start_period = list_of_cols[col_pointer]\n",
    "                            duration = col_pointer\n",
    "                        resident_country = new_resident_country\n",
    "                        col_pointer+=sliding_window_nr_of_cols\n",
    "                        nr_of_consecutive_cols_to_find = 1\n",
    "                        # col_pointer is moved sliding_window_nr_of_cols \n",
    "                        # and search modus is 1-step\n",
    "\n",
    "\n",
    "                    else: #no real new resident country found\n",
    "                        # meaning the new resident country will become in transit, because no_data is not an option:\n",
    "                        # the column in this 1 step cannot be 'no_data', because length of of initial res_dict > 0\n",
    "                        if not first_residence_country_found: #this is the first residence country\n",
    "                                    first_residence_country_found = True\n",
    "                                    start_period = list_of_cols[col_pointer]\n",
    "                                    duration = col_pointer\n",
    "                        else: #store previous residence country\n",
    "                                    resident_country_list.extend([{'user':u,'residence_country':resident_country,'start_period':start_period,'duration':col_pointer - duration}])\n",
    "                                    start_period = list_of_cols[col_pointer]\n",
    "                                    duration = col_pointer \n",
    "\n",
    "                        #double check if there is really data:\n",
    "                        if df_user_window[list_of_cols[col_pointer]].values.sum() == 0:\n",
    "                                print(\"ERROR: expected data, but found no_data.\")\n",
    "                                print(df_user_list_of_dict)     \n",
    "\n",
    "                        for i in df_user_list_of_dict: #set all real countrys to 0\n",
    "                            i[list_of_cols[col_pointer]] = 0\n",
    "                        df_user_list_of_dict[-2][list_of_cols[col_pointer]] = 1 # set in_transit to 1\n",
    "                        resident_country = 'in_transit'\n",
    "                        # nr of cols for next resident country is full sice of sliding_window_nr_of_cols\n",
    "                        nr_of_consecutive_cols_to_find = sliding_window_nr_of_cols\n",
    "                        #shift window one month to the next col:\n",
    "                        col_pointer += 1\n",
    "\n",
    "                        #process end of data / last columns:\n",
    "                else: #the new_resident_country is the same as the already existing resident_country\n",
    "                    nr_of_consecutive_cols_to_find = 1  # in next loop check only the next col to see if 1 consecutive country is in it \n",
    "                    col_pointer += 1   \n",
    "            else: #len of col_list is 3, these 3 cols have been analysed and a new resident country has been found \n",
    "                #track resident periods per users:\n",
    "                if not first_residence_country_found: #this is the first residence country\n",
    "                            first_residence_country_found = True\n",
    "                            start_period = list_of_cols[col_pointer]\n",
    "                            duration = col_pointer\n",
    "                else: #store previous residence country\n",
    "                            resident_country_list.extend([{'user':u,'residence_country':resident_country,'start_period':start_period,'duration':col_pointer - duration}])\n",
    "                            start_period = list_of_cols[col_pointer]\n",
    "                            duration = col_pointer                            \n",
    "                \n",
    "                resident_country = new_resident_country\n",
    "                nr_of_consecutive_cols_to_find = 1 #single steps until change in country\n",
    "                col_pointer += sliding_window_nr_of_cols   #start next loop beyond these 3 cols belonging to new resident country\n",
    "\n",
    "        else: #no potential resident_country found: column needs to be set either to in_transit or to no_data\n",
    "            # to check if there was no data  all values are summarized across df and col_list: \n",
    "            # formula: df_user_window[list_of_cols[col_pointer]].values.sum()\n",
    "            # values only for the column at col_pointer\n",
    "            # exception: if col == first_col, it should be treated as resident\n",
    "\n",
    "            #track resident periods per users:\n",
    "            if not first_residence_country_found: #this is the first residence country\n",
    "                        first_residence_country_found = True\n",
    "                        start_period = list_of_cols[col_pointer]\n",
    "                        duration = col_pointer\n",
    "            else: #store previous residence country\n",
    "                        resident_country_list.extend([{'user':u,'residence_country':resident_country,'start_period':start_period,'duration':col_pointer - duration}])\n",
    "                        start_period = list_of_cols[col_pointer]\n",
    "                        duration = col_pointer        \n",
    "\n",
    "            for i in df_user_list_of_dict: #set all real countrys to 0\n",
    "                    i[list_of_cols[col_pointer]] = 0\n",
    "\n",
    "            if df_user_window[list_of_cols[col_pointer]].values.sum() >0: #if true, col is in_transit, if otherwise no_data\n",
    "                resident_country = 'in_transit'\n",
    "                df_user_list_of_dict[-2][list_of_cols[col_pointer]] = 1 # set in transit to 1\n",
    "            else:\n",
    "                resident_country = 'no_data'\n",
    "                df_user_list_of_dict[-1][list_of_cols[col_pointer]] = 1 \n",
    "\n",
    "\n",
    "            nr_of_consecutive_cols_to_find = sliding_window_nr_of_cols\n",
    "            # next loop only 1 column shift:\n",
    "            col_pointer += 1\n",
    "            if col_pointer+sliding_window_nr_of_cols > nr_of_month+2: #exception processing for the last two columns\n",
    "                # df2 = pd.DataFrame(df_user_list_of_dict)\n",
    "                # df2.to_excel(\"check_user_output.xlsx\")\n",
    "                break\n",
    "                for new_col_pointer in range(col_pointer, len(df_user_list_of_dict[1])):\n",
    "                    count_zero = 0\n",
    "                    for i in df_user_list_of_dict:\n",
    "                        count = i[list_of_cols[new_col_pointer]]\n",
    "                        count_zero += count\n",
    "                    if count_zero == 0:\n",
    "                        for i in df_user_list_of_dict:\n",
    "                \n",
    "                            i[list_of_cols[new_col_pointer]] = 0\n",
    "                    \n",
    "                        df_user_list_of_dict[-1][list_of_cols[new_col_pointer]] = 1 \n",
    "                        resident_country = 'no_data'\n",
    "                    else:\n",
    "\n",
    "                        for i in df_user_list_of_dict:\n",
    "                            i[list_of_cols[new_col_pointer]] = 0\n",
    "                        df_user_list_of_dict[-2][list_of_cols[new_col_pointer]] = 1\n",
    "                        resident_country = 'in_transit'\n",
    "\n",
    "    if first_residence_country_found: \n",
    "        #store last residence country\n",
    "            resident_country_list.extend([{'user':u,'residence_country':resident_country,'start_period':start_period,'duration':col_pointer - duration}])\n",
    "                                    \n",
    "    user_residence_periods_dict[u] = resident_country_list\n",
    "    df_result = pd.concat([df_result,pd.DataFrame(df_user_list_of_dict)],ignore_index=True)     \n",
    "        \n",
    "df_user_residence_periods = pd.DataFrame(resident_country_list)\n",
    "df_user_residence_periods.to_csv(\"user_residence_periods.csv\")\n",
    "df_result.to_csv(outputfile)\n",
    "\n",
    "print('Done') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "Residents_Sliding = pd.read_csv('resident_user_by_country_by_month_in_cols_sliding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Residents_VE = Residents_Sliding[Residents_Sliding.country == 'VE']\n",
    "Residents_other = Residents_Sliding[Residents_Sliding.country == 'other']\n",
    "Residents_CO = Residents_Sliding[Residents_Sliding.country == 'CO']\n",
    "Residents_transit = Residents_Sliding[Residents_Sliding.country == 'in_transit']\n",
    "Residents_data = Residents_Sliding[Residents_Sliding.country == 'no data']\n",
    "Residents_data = Residents_data.replace({0: 1, 1: 0})\n",
    "\n",
    "\n",
    "count_VE= Residents_VE.iloc[:, 6:-3].sum()/Residents_data.iloc[:, 6:-3].sum()*100\n",
    "count = Residents_CO.iloc[:, 6:-3].sum()/Residents_data.iloc[:, 6:-3].sum()*100\n",
    "count_other = Residents_other.iloc[:, 6:-3].sum()/Residents_data.iloc[:, 6:-3].sum()*100\n",
    "count_all = Residents_data.iloc[:, 6:-3].sum()\n",
    "count_transit = Residents_transit.iloc[:, 6:-3].sum()/Residents_data.iloc[:, 6:-3].sum()*100\n",
    "plt.plot(count.index, count.values, color = 'blue', label='Residents in Colombia')\n",
    "plt.plot(count_VE.index, count_VE.values, color='red', label='Residents in Venezuela')\n",
    "plt.plot(count_other.index, count_other.values, color='green', label='Residents globally')\n",
    "#plt.plot(count_all.index, count_all.values, color='black', label='All Users')\n",
    "plt.plot(count_transit.index, count_transit.values, color='purple', label='Users in transit')\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(count.index[::3], count.index[::3], rotation=90)\n",
    "plt.xticks()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Percentage of active users')\n",
    "plt.title('Percentage of active users as residents: Sliding window ')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig('Residents_perMonth_Exclusive_sliding.png',  dpi=300)\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(row):\n",
    "    sequences = []\n",
    "    start_col = ''\n",
    "    found_start = False\n",
    "    \n",
    "    for col in row.index:\n",
    "        if row[col] == 1 and not found_start:\n",
    "            start_col = col\n",
    "            found_start = True\n",
    "        elif row[col] == 0 and found_start:\n",
    "            end_col = col\n",
    "            sequences.append((start_col, end_col))\n",
    "            found_start = False\n",
    "    \n",
    "    # Check if the last sequence continues until the end of the row\n",
    "    if found_start:\n",
    "        sequences.append((start_col, row.index[-1]))\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find most frequent tweet location\n",
    "def process_tweet(row, valid_row):\n",
    "    Place_ID = row['Place_ID']\n",
    "    Full_name = row['full_name']\n",
    "    if Place_ID not in valid_row:\n",
    "        valid_row[Place_ID] = {}\n",
    "        valid_row\n",
    "        valid_row[Place_ID]['Full_name'] = Full_name\n",
    "        valid_row[Place_ID]['Place_ID'] = Place_ID\n",
    "        valid_row[Place_ID]['Occurence'] = 1\n",
    "    else:\n",
    "        valid_row[Place_ID]['Occurence'] += 1\n",
    "    return valid_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "Users = [str(i) for i in Users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "Residents_Sliding.user = [str(i) for i in Residents_Sliding.user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_tweets['Created_At'] = pd.to_datetime(All_tweets['Created_At'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "Users = [int(i) for i in Users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract users that are Venezuelan residents and from the Venezuelan residents those who have also been Colombian residents\n",
    "# Create a dictionary for all migrants summarizing their cities of residence during their resident periods in Colombia\n",
    "\n",
    "Ve_Residents_sliding = []\n",
    "CO_Residents_sliding = []\n",
    "Migrant_dict_sliding = {}\n",
    "timezone = pytz.timezone('UTC')\n",
    "recurrent_sliding = []\n",
    "Ratios_sliding = []\n",
    "\n",
    "\n",
    "now = dt.datetime.now(timezone)\n",
    "for u in Users:\n",
    "  \n",
    "    User_df = Residents_Sliding[Residents_Sliding.user == u].copy()\n",
    "    \n",
    "    VE = User_df[User_df.country == 'VE']\n",
    "    CO = User_df[User_df.country == 'CO']\n",
    "\n",
    "    # If at least one residence period found in Venezuela, user becomes Venezuelan resident\n",
    "\n",
    "    if VE.iloc[:,3:].sum().sum() != 0:\n",
    "        Ve_Residents_sliding.append(u)\n",
    "       \n",
    "        # For Venezuelan residents it is also checked, whether they are Colombian residents\n",
    "\n",
    "        if CO.iloc[:,3:].sum().sum() !=0:\n",
    "            CO_Residents_sliding.append(u)\n",
    "  \n",
    "            user_id = str(u)\n",
    "\n",
    "            #Resulting migrants are added to dictionary\n",
    "\n",
    "            Migrant_dict_sliding[user_id]={}\n",
    "            Migrant_dict_sliding[user_id]['Entire_Residence_Period_CO']= pd.Timedelta(0)\n",
    "            Migrant_dict_sliding[user_id]['Entire_Residence_Period_VE']= pd.Timedelta(0)\n",
    "            # Extract the start and end dates of all residence periods\n",
    "\n",
    "            sequences_CO = CO.iloc[:,3:].apply(lambda row: get_sequences(row), axis=1)\n",
    "            sequences_VE = VE.iloc[:,3:].apply(lambda row: get_sequences(row), axis=1)\n",
    "            print(sequences_CO)\n",
    "            for index, row_sequences in sequences_CO.items():\n",
    "                for i, (start, end) in enumerate(row_sequences):\n",
    "                    \n",
    "                    year_str = start[2:]\n",
    "                    month_str = start[:2]\n",
    "\n",
    "                    year_int = int(year_str)\n",
    "                    month_int = int(month_str)\n",
    "                    period_start = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                    \n",
    "                    \n",
    "                    year_str = end[2:]\n",
    "                    month_str = end[:2]\n",
    "                    year_int = int(year_str)\n",
    "                    month_int = int(month_str)\n",
    "\n",
    "                    period_end = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                    period_end = period_end.replace(day=28) + dt.timedelta(days=4)\n",
    "                    period_end = period_end - dt.timedelta(days=period_end.day)\n",
    "                    if i == 0:\n",
    "                        first_start_CO = period_start\n",
    "                    #Extract the specific user's tweets during the period\n",
    "\n",
    "                    Tweet_df = All_tweets[All_tweets.User_ID == u].copy()\n",
    "                    Tweet_df_in_residence_period = Tweet_df[(Tweet_df['Created_At'] >= period_start) & (Tweet_df['Created_At'] <= period_end) & (Tweet_df['Place'] == 'CO')].copy()\n",
    "                    \n",
    "                    # Check all places in colombia that the migrant visited during their residence period\n",
    "\n",
    "                    valid_row = {}                          \n",
    "                    Tweet_df_in_residence_period.apply(process_tweet, axis=1, args=(valid_row,))\n",
    "                    Diff = period_end-period_start\n",
    "                    Migrant_dict_sliding[user_id]['Entire_Residence_Period_CO'] += Diff\n",
    "\n",
    "                    # Find the dictionary with the highest Occurence value in valid_row\n",
    "                    Max_Duration = max(valid_row.values(), key=lambda x: x['Occurence'])\n",
    "                    Exact_Loc = Max_Duration\n",
    "                    # Add Exact_Loc to Migrant_dict\n",
    "                    period = f'{start}_{end}'\n",
    "                    print(Diff, u, period)\n",
    "                    Migrant_dict_sliding[user_id][period] = Exact_Loc \n",
    "                    \n",
    "                    \n",
    "                for index, row_sequences in sequences_VE.items():\n",
    "                    for i, (start, end) in enumerate(row_sequences):\n",
    "                    \n",
    "                        year_str = start[2:]\n",
    "                        month_str = start[:2]\n",
    "\n",
    "                        year_int = int(year_str)\n",
    "                        month_int = int(month_str)\n",
    "                        period_start = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                        \n",
    "                        \n",
    "                        year_str = end[2:]\n",
    "                        month_str = end[:2]\n",
    "                        year_int = int(year_str)\n",
    "                        month_int = int(month_str)\n",
    "\n",
    "                        period_end = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                        period_end = period_end.replace(day=28) + dt.timedelta(days=4)\n",
    "                        period_end = period_end - dt.timedelta(days=period_end.day)\n",
    "                        if period_start > first_start_CO:\n",
    "                            Diff_VE = period_end - period_start\n",
    "                            print(Diff_VE, u, period_start, period_end)\n",
    "                            Migrant_dict_sliding[user_id]['Entire_Residence_Period_VE'] += Diff_VE\n",
    "                        if i == 0:\n",
    "                            first_start_VE = period_start\n",
    "                            first_end_VE = period_end\n",
    "\n",
    "                try:\n",
    "                    Total =  Migrant_dict_sliding[user_id]['Entire_Residence_Period_CO'] + Migrant_dict_sliding[user_id]['Entire_Residence_Period_VE']         \n",
    "                    Ratio =  Migrant_dict_sliding[user_id]['Entire_Residence_Period_CO']/Total\n",
    "                    Ratios_sliding.append(Ratio)\n",
    "                    if Ratio < 0.5:\n",
    "                        recurrent_sliding.append(u)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "              \n",
    "                \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recurrent_sliding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022\n",
      "2695\n"
     ]
    }
   ],
   "source": [
    "print(len(CO_Residents_sliding))\n",
    "print(len(Ve_Residents_sliding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Ratios_sliding\n",
    "\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=20)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Ratio')\n",
    "plt.ylabel('Users')\n",
    "plt.title('Distribution of ratios: Sliding window')\n",
    "\n",
    "# Display the histogram\n",
    "plt.savefig('Rations_modal_sliding.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_sliding = [str(i) for i in recurrent_sliding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO_Residents_sliding = [str(i) for i in CO_Residents_sliding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "Residents_Sliding.user = [str(i) for i in Residents_Sliding.user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_tweets.User_ID = [str(i) for i in All_tweets.User_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each non-recurrent migrant, find the Colombian city in which they last were detected to be resident and check if afterwards they returned to Venezuela or not\n",
    "\n",
    "timezone = pytz.timezone('UTC')\n",
    "now = dt.datetime.now(timezone)\n",
    "Not_Returned = []\n",
    "Last_Residence_dict= {}\n",
    "Returned = []\n",
    "Moved_on = []\n",
    "recurrent_bymonth = []\n",
    "\n",
    "for u in CO_Residents_sliding:\n",
    "\n",
    "    #Not considering recurrent migrants\n",
    "\n",
    "    if u not in recurrent_sliding:\n",
    "        User_df = Residents_Sliding[Residents_Sliding.user == u]\n",
    "\n",
    "        VE = User_df[User_df.country == 'VE']\n",
    "        CO = User_df[User_df.country == 'CO']\n",
    "        Other = User_df[User_df.country == 'other']\n",
    "        \n",
    "        if VE.iloc[:,3:].sum().sum() != 0:\n",
    "       \n",
    "\n",
    "            if CO.iloc[:,3:].sum().sum() !=0:\n",
    "            \n",
    "        \n",
    "\n",
    "           \n",
    "                # Find all residence periods \n",
    "\n",
    "                sequences_CO = CO.iloc[:,3:].apply(lambda row: get_sequences(row), axis=1)\n",
    "                sequences_VE = VE.iloc[:,3:].apply(lambda row: get_sequences(row), axis=1)\n",
    "                sequences_other = Other.iloc[:,3:].apply(lambda row: get_sequences(row), axis=1)\n",
    "                print(sequences_CO)\n",
    "                for index, row_sequences in sequences_CO.items():\n",
    "                    \n",
    "                    if len(row_sequences) > 0:\n",
    "\n",
    "                        # Extract start and end dates of the residence periods\n",
    "                        last_sequence = row_sequences[-1]\n",
    "                        start, end = last_sequence\n",
    "                        \n",
    "                        year_str = start[2:]\n",
    "                        month_str = start[:2]\n",
    "\n",
    "                        year_int = int(year_str)\n",
    "                        month_int = int(month_str)\n",
    "                        period_start_CO = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                        \n",
    "                        \n",
    "                        year_str = end[2:]\n",
    "                        month_str = end[:2]\n",
    "                        year_int = int(year_str)\n",
    "                        month_int = int(month_str)\n",
    "\n",
    "                        period_end = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                        period_end = period_end.replace(day=28) + dt.timedelta(days=4)\n",
    "                        period_end_CO = period_end - dt.timedelta(days=period_end.day)   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        Tweet_df = All_tweets[All_tweets.User_ID == u].copy()\n",
    "                        print(Tweet_df)\n",
    "                        Tweet_df_in_residence_period = Tweet_df[(Tweet_df['Created_At'] >= period_start_CO) & (Tweet_df['Created_At'] <= period_end_CO) & (Tweet_df['Place'] == 'CO')].copy()\n",
    "                        valid_row = {}                          \n",
    "                        Tweet_df_in_residence_period.apply(process_tweet, axis=1, args=(valid_row,))\n",
    "                                            \n",
    "                                            \n",
    "                 \n",
    "\n",
    "                        \n",
    "                    # Find the dictionary with the highest Occurence value in valid_row\n",
    "                        Max_Duration = max(valid_row.values(), key=lambda x: x['Occurence'])\n",
    "                        Full_name = Max_Duration['Full_name']\n",
    "                        Exact_Loc = Max_Duration\n",
    "                        for index, row_sequences in sequences_other.items():\n",
    "                            if len(row_sequences) > 0:\n",
    "                                last_sequence = row_sequences[-1]\n",
    "                                start, end = last_sequence\n",
    "                                \n",
    "                                year_str = start[2:]\n",
    "                                month_str = start[:2]\n",
    "\n",
    "                                year_int = int(year_str)\n",
    "                                month_int = int(month_str)\n",
    "                                period_start_other = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                                if period_start_other>period_start_CO:\n",
    "\n",
    "                                    Moved_on.append(u)\n",
    "\n",
    "                \n",
    "                for index, row_sequences in sequences_VE.items():\n",
    "                    if len(row_sequences) > 0:\n",
    "                        last_sequence = row_sequences[-1]\n",
    "                        start, end = last_sequence\n",
    "                            \n",
    "                        year_str = start[2:]\n",
    "                        month_str = start[:2]\n",
    "\n",
    "                        year_int = int(year_str)\n",
    "                        month_int = int(month_str)\n",
    "                        period_start_VE = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                \n",
    "                Diff = (period_end_CO-period_start_CO)              \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                if Full_name not in Last_Residence_dict:\n",
    "                    Last_Residence_dict[Full_name] = {}\n",
    "                    Last_Residence_dict[Full_name]['Returned_2022'] = 0\n",
    "                    Last_Residence_dict[Full_name]['Not_Returned_2022'] = 0\n",
    "                    Last_Residence_dict[Full_name]['Not_Returned'] = 0\n",
    "                    Last_Residence_dict[Full_name]['Returned'] = 0\n",
    "                    Last_Residence_dict[Full_name]['Residents_Time_Not_Returned'] = period_end_CO-period_end_CO\n",
    "                    Last_Residence_dict[Full_name]['Residents_Time_Returned'] = period_end_CO-period_end_CO\n",
    "                if u not in Moved_on:\n",
    "                    if period_start_CO > period_start_VE:\n",
    "                        \n",
    "                        Last_Residence_dict[Full_name]['Residents_Time_Not_Returned'] += Diff\n",
    "                        Last_Residence_dict[Full_name]['Not_Returned'] += 1\n",
    "                        Not_Returned.append(u)\n",
    "                        if period_end_CO.year == 2022:\n",
    "                            Last_Residence_dict[Full_name]['Not_Returned_2022'] +=1\n",
    "                    else: \n",
    "                        Last_Residence_dict[Full_name]['Returned'] += 1\n",
    "                        Last_Residence_dict[Full_name]['Residents_Time_Returned'] += Diff\n",
    "                        Returned.append(u)\n",
    "                        if period_start_VE.year == 2022:\n",
    "                            Last_Residence_dict[Full_name]['Returned_2022'] +=1\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "266\n",
      "308\n"
     ]
    }
   ],
   "source": [
    "print(len(Moved_on))\n",
    "print(len(Returned))\n",
    "print(len(Not_Returned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transorm the dictionary with the last cities of residence to a dataframe\n",
    "\n",
    "last_resident_city_sliding= pd.DataFrame(Last_Residence_dict).T\n",
    "\n",
    "#Add the total count of migrants in the city\n",
    "\n",
    "last_resident_city_sliding['total'] = last_resident_city_sliding['Not_Returned'] + last_resident_city_sliding['Returned']\n",
    "last_resident_city_sliding.sort_values('total', ascending=False, inplace=True)\n",
    "\n",
    "# Find the average time spent in the city of last residence for returned and not returned migrants\n",
    "\n",
    "last_resident_city_sliding.replace(0, np.nan, inplace=True)\n",
    "last_resident_city_sliding['Residents_Time_Not_Returned_Average'] = (last_resident_city_sliding['Residents_Time_Not_Returned']/ last_resident_city_sliding['Not_Returned'])\n",
    "last_resident_city_sliding['Residents_Time_Returned_Average'] = last_resident_city_sliding['Residents_Time_Returned']/ (last_resident_city_sliding['Returned'])\n",
    "last_resident_city_sliding.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_resident_city_sliding_ratio = last_resident_city_sliding.drop(columns=last_resident_city_sliding.columns[2:], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_resident_city_sliding_ratio['Ratio_22'] = last_resident_city_sliding_ratio['Returned_2022']/last_resident_city_sliding_ratio['Not_Returned_2022']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_resident_city_sliding_ratio = last_resident_city_sliding_ratio.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_resident_city_sliding_ratio.sort_values('Ratio_22', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "Not_Returned = [str(i) for i in Not_Returned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "Returned = [str(i) for i in Returned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_sliding = [str(i) for i in recurrent_sliding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for a ll returned migrants where their time of residence in Colombia us summed up. the diffrent places they stayed and the number of Colombian residence periods can be found in the Twitter data\n",
    "Returned_dict_sliding =  {}\n",
    "for k, v in Migrant_dict_sliding.items():\n",
    "    if k in Returned:\n",
    "        Returned_dict_sliding[k] = {}\n",
    "        Number_of_res_periods = (len(v)-2)\n",
    "        Duration = v['Entire_Residence_Period_CO']\n",
    "        dict_view = v.items()\n",
    "        IDs = set()\n",
    "        for key, value in itertools.islice(dict_view, 2, None):\n",
    "            Place_ID = value['Place_ID']\n",
    "            IDs.add(Place_ID)\n",
    "\n",
    "\n",
    "\n",
    "        Returned_dict_sliding[k]['Periods'] = Number_of_res_periods\n",
    "        Returned_dict_sliding[k]['Different_Places'] = len(IDs)\n",
    "        Returned_dict_sliding[k]['Duration'] = Duration\n",
    "           \n",
    "\n",
    "Returned_df_sliding = pd.DataFrame(Returned_dict_sliding).T\n",
    "Returned_df_sliding.sort_values('Periods', ascending=False, inplace=True)\n",
    "Returned_df_sliding.to_csv('Returned_df_sliding.csv')\n",
    "\n",
    "\n",
    "Moved_on = [str(i) for i in Moved_on]\n",
    "\n",
    "Not_returned_dict_sliding =  {}\n",
    "for k, v in Migrant_dict_sliding.items():\n",
    "    if k in Not_Returned:\n",
    "        if k not in Moved_on:\n",
    "            Not_returned_dict_sliding[k] = {}\n",
    "            Number_of_res_periods = (len(v)-2)\n",
    "            Duration = v['Entire_Residence_Period_CO']\n",
    "            dict_view = v.items()\n",
    "            IDs = set()\n",
    "            for key, value in itertools.islice(dict_view, 2, None):\n",
    "                Place_ID = value['Place_ID']\n",
    "                IDs.add(Place_ID)\n",
    "\n",
    "\n",
    "\n",
    "            Not_returned_dict_sliding[k]['Periods'] = Number_of_res_periods\n",
    "            Not_returned_dict_sliding[k]['Different_Places'] = len(IDs)\n",
    "            Not_returned_dict_sliding[k]['Duration'] = Duration\n",
    "           \n",
    "Not_returned_df_sliding = pd.DataFrame(Not_returned_dict_sliding).T\n",
    "Not_returned_df_sliding.sort_values('Periods', ascending=False, inplace=True)\n",
    "Not_returned_df_sliding.to_csv('Not_returned_df_sliding.csv')\n",
    "Not_returned_df_sliding.head(10)\n",
    "Recurrent_dict_sliding =  {}\n",
    "for k, v in Migrant_dict_sliding.items():\n",
    "    IDs = set()\n",
    "    if k in recurrent_sliding:\n",
    "\n",
    "        Recurrent_dict_sliding[k] = {}\n",
    "        Number_of_res_periods = (len(v)-2)\n",
    "        Duration = v['Entire_Residence_Period_CO']\n",
    "        dict_view = v.items()\n",
    "        for key, value in itertools.islice(dict_view, 2, None):\n",
    "            \n",
    "            Place_ID = value['Place_ID']\n",
    "            IDs.add(Place_ID)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Recurrent_dict_sliding[k]['Periods'] = Number_of_res_periods\n",
    "        Recurrent_dict_sliding[k]['Different_Places'] = len(IDs)\n",
    "        Recurrent_dict_sliding[k]['Duration'] = Duration\n",
    "           \n",
    "Recurrent_df_sliding = pd.DataFrame(Recurrent_dict_sliding).T\n",
    "Recurrent_df_sliding.sort_values('Periods', ascending=False, inplace=True)\n",
    "Recurrent_df_sliding.to_csv('Recurrent_df_sliding.csv')\n",
    "Recurrent_df_sliding.head(10)\n",
    "len(Recurrent_df_sliding)\n",
    "Average_periods_returned = Returned_df_sliding['Periods'].sum()/len(Returned_df_sliding)\n",
    "Average_places_returned = Returned_df_sliding['Different_Places'].sum()/len(Returned_df_sliding)\n",
    "Average_duration_returned = Returned_df_sliding['Duration'].dt.days.sum()/len(Returned_df_sliding)\n",
    "Average_periods_returned = Returned_df_sliding['Periods'].sum()/len(Returned_df_sliding)\n",
    "\n",
    "Average_periods_not_returned = Not_returned_df_sliding['Periods'].sum()/len(Not_returned_df_sliding)\n",
    "Average_places_not_returned = Not_returned_df_sliding['Different_Places'].sum()/len(Not_returned_df_sliding)\n",
    "Average_duration_not_returned = Not_returned_df_sliding['Duration'].dt.days.sum()/len(Not_returned_df_sliding)\n",
    "Average_periods_not_returned = Not_returned_df_sliding['Periods'].sum()/len(Not_returned_df_sliding)\n",
    "\n",
    "\n",
    "Average_periods_recurrent = Recurrent_df_sliding['Periods'].sum()/len(Recurrent_df_sliding)\n",
    "Average_places_recurrent = Recurrent_df_sliding['Different_Places'].sum()/len(Recurrent_df_sliding)\n",
    "Average_duration_recurrent = Recurrent_df_sliding['Duration'].dt.days.sum()/len(Recurrent_df_sliding)\n",
    "Average_periods_recurrent = Recurrent_df_sliding['Periods'].sum()/len(Recurrent_df_sliding)\n",
    "\n",
    "Average_dict = {}\n",
    "Average_dict['Average_duration_not_returned'] = Average_duration_not_returned\n",
    "Average_dict['Average_duration_returned'] = Average_duration_returned\n",
    "Average_dict['Average_duration_recurrent'] = Average_duration_recurrent\n",
    "Average_dict['Average_places_not_returned'] = Average_places_not_returned\n",
    "Average_dict['Average_places_recurrent'] = Average_places_recurrent\n",
    "Average_dict['Average_places_returned'] = Average_places_returned\n",
    "Average_dict['Average_periods_not_returned'] = Average_periods_not_returned\n",
    "Average_dict['Average_periods_returned'] = Average_periods_returned\n",
    "Average_dict['Average_periods_recurrent'] = Average_periods_recurrent\n",
    "\n",
    "Average_df = pd.DataFrame(Average_dict, index=(Average_dict.values()))\n",
    "Average_df = Average_df.T\n",
    "\n",
    "Average_df.rename(columns={346.400685: 'Average'},  inplace=True)\n",
    "Average_df.drop(columns=Average_df.columns[1:], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Average_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "Average_df.rename(index={'Average_duration_not_returned':'Duration Not Returned', 'Average_duration_returned': 'Duration Returned', 'Average_places_not_returned': 'Places Not Returned', 'Average_places_returned': 'Places Returned', 'Average_periods_not_returned': 'Periods Not Returned', 'Average_periods_returned': 'Periods Returned', 'Average_duration__recurrent': 'Duration Recurrent', 'Average_places_recurrent': 'Places Recurrent', 'Average_periods_recurrent': 'Periods Recurrent'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Average_df.rename(columns={Average_df.columns[0]:'Average'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to find coefficient of variation \n",
    "cv = lambda x: np.std(x, ddof=1) / np.mean(x) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the most commonly chosen cities as places of residence and how many migrants can be detected per month in each city: Including recurrent migrants\n",
    "\n",
    "Most_Common = {}\n",
    "Months_Dicts = {}\n",
    "for user, value in Migrant_dict_sliding.items():\n",
    "    for k, v in value.items():\n",
    "        if (k != 'Entire_Residence_Period_CO') & (k!= 'Entire_Residence_Period_VE'):\n",
    "        \n",
    "            \n",
    "            \n",
    "            for e, val in v.items():\n",
    "                if e == 'Full_name':\n",
    "                    Place_name= val\n",
    "                if e == 'Place_ID':\n",
    "                    Place_ID = val\n",
    "                    periods = k.split('_')\n",
    "                    if Place_name not in Months_Dicts:\n",
    "               \n",
    "                        Months_Dicts[Place_name] = {}\n",
    "                        for year in range(2018, 2023):\n",
    "                            for month in range(1, 13):\n",
    "                                # Create a key for the month, with leading zeros if necessary (e.g., '2018_01')\n",
    "                                key = f\"{year}_{month:02d}\"\n",
    "                                # Assign an initial value of None to the key\n",
    "                                Months_Dicts[Place_name][key] = 0\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    start = periods[0]\n",
    "                    end = periods[1]\n",
    "               \n",
    "                    start_month = start[:2]\n",
    "                    start_year = start[2:]\n",
    "                    end_month = end[:2]\n",
    "                    end_year = end[2:]\n",
    "    \n",
    "                    if int(start_month) > int(end_month):\n",
    "                        for year in range(int(start_year), int(end_year) + 1):\n",
    "                            for month in range(int(start_month), 13):\n",
    "                                if year == int(end_year):\n",
    "                                    continue \n",
    "                                Occ = f\"{year}_{month:02d}\"\n",
    "                                for key in Months_Dicts[Place_name].keys():\n",
    "                                    if Occ == key:\n",
    "                                        Months_Dicts[Place_name][key] += 1\n",
    "                                      \n",
    "\n",
    "                            for month in range(1, int(end_month) + 1):\n",
    "                                if year == int(start_year):\n",
    "                                    continue\n",
    "                                Occ = f\"{year}_{month:02d}\"\n",
    "                                for key in Months_Dicts[Place_name].keys():\n",
    "                                    if Occ == key:\n",
    "                              \n",
    "                                        Months_Dicts[Place_name][key] += 1\n",
    "                                     \n",
    "\n",
    "                    else:\n",
    "                        for year in range(int(start_year), int(end_year) + 1):\n",
    "                            for month in range(int(start_month), int(end_month) + 1):\n",
    "                                Occ = f\"{year}_{month:02d}\"\n",
    "                                for key in Months_Dicts[Place_name].keys():\n",
    "                                    if Occ == key:\n",
    "                                    \n",
    "                                        Months_Dicts[Place_name][key] += 1\n",
    "                                        \n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    if Place_name in Most_Common:\n",
    "                        Most_Common[Place_name]['Total'] += 1\n",
    "                    else:\n",
    "                        Most_Common[Place_name]= {}\n",
    "                        \n",
    "                        Most_Common[Place_name]['Others'] = 0\n",
    "                        Most_Common[Place_name]['Recurrent'] = 0\n",
    "                        Most_Common[Place_name]['Total'] = 1\n",
    "                        Most_Common[Place_name]['ID'] = Place_ID\n",
    "                    if user in recurrent_sliding:\n",
    "                        Most_Common[Place_name]['Recurrent'] += 1\n",
    "            \n",
    "\n",
    "                    else:\n",
    "                        Most_Common[Place_name]['Others'] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and add a 'Total' row which sums up the migrants in CO per month\n",
    "\n",
    "Months_df_sliding_recurrent = pd.DataFrame(Months_Dicts)\n",
    "Months_df_sliding_recurrent = Months_df_sliding_recurrent.T\n",
    "Months_df_sliding_recurrent.loc['Total'] = Months_df_sliding_recurrent.sum(axis=0)\n",
    "\n",
    "Months_df_sliding_recurrent.to_csv('Months_df_sliding_recurrent.csv')\n",
    "\n",
    "# Select time periods to analyze: Inluding recurrent\n",
    "\n",
    "months_df_month_22_recurrent = Months_df_sliding_recurrent.drop(columns=Months_df_sliding_recurrent.columns[:48], axis=1)\n",
    "months_df_feb_22_recurrent = months_df_month_22_recurrent[['2022_02']]\n",
    "Jan_to_March_df_22_recurrent = Months_df_sliding_recurrent.iloc[:, 48:51]\n",
    "\n",
    "# Add column with average value per city over the time period selected: Including recurrent\n",
    "\n",
    "Jan_to_March_df_22_recurrent['Mean'] =Jan_to_March_df_22_recurrent.mean(axis=1)\n",
    "months_df_month_22_recurrent['Mean'] =months_df_month_22_recurrent.mean(axis=1)\n",
    "months_df_feb_22_recurrent['Mean'] =months_df_feb_22_recurrent.mean(axis=1)\n",
    "\n",
    "\n",
    "# Sort values: Including recurrent\n",
    "\n",
    "Cities_top_22_recurrent = months_df_month_22_recurrent.sort_values('Mean', ascending=False).head(10)\n",
    "Cities_top_feb_recurrent = months_df_feb_22_recurrent.sort_values('Mean', ascending=False).head(20)\n",
    "Cities_top_Jan_to_March_recurrent = Jan_to_March_df_22_recurrent.sort_values('Mean', ascending=False).head(10)\n",
    "\n",
    "# Upscale the city values according to the ratio of migrants to the number of migrants found per city\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "Result_df_city_migrants_upscaled_sliding_feb_recurrent = pd.DataFrame(2477588/Cities_top_feb_recurrent.at['Total', 'Mean'] * Cities_top_feb_recurrent['Mean'])\n",
    "\n",
    "Result_df_city_migrants_upscaled_sliding_JanMarch_reccurent = pd.DataFrame(2477588/Cities_top_Jan_to_March_recurrent.at['Total', 'Mean'] * Cities_top_Jan_to_March_recurrent['Mean'])\n",
    "\n",
    "Result_df_city_migrants_upscaled_sliding_22_recurrent = pd.DataFrame(2477588/Cities_top_22_recurrent.at['Total', 'Mean'] * Cities_top_22_recurrent['Mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_Bogota_22 = 495236\n",
    "official_Medellin_22 = 190854\n",
    "official_Cucuta_22 = 167678\n",
    "official_Candelaria_22 = 121837\n",
    "official_Bucaramanga_22 = 52128\n",
    "official_Barranquilla_22 = 112895\n",
    "official_Cartagena_22 = 70201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022_02</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>191</td>\n",
       "      <td>191.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bogot, D.C., Colombia</th>\n",
       "      <td>59</td>\n",
       "      <td>59.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medelln, Colombia</th>\n",
       "      <td>22</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ccuta, Colombia</th>\n",
       "      <td>12</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cartagena, Colombia</th>\n",
       "      <td>8</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barranquilla, Colombia</th>\n",
       "      <td>6</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Candelaria, Colombia</th>\n",
       "      <td>6</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rionegro, Colombia</th>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Patios, Colombia</th>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bucaramanga, Colombia</th>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Santa Marta, Colombia</th>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Envigado, Colombia</th>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ibagu, Colombia</th>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facatativ, Colombia</th>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valledupar, Colombia</th>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valle del Cauca, Colombia</th>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Villavicencio, Colombia</th>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Riohacha, Colombia</th>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soledad, Colombia</th>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arauca, Colombia</th>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           2022_02   Mean\n",
       "Total                          191 191.00\n",
       "Bogot, D.C., Colombia          59  59.00\n",
       "Medelln, Colombia              22  22.00\n",
       "Ccuta, Colombia                12  12.00\n",
       "Cartagena, Colombia              8   8.00\n",
       "Barranquilla, Colombia           6   6.00\n",
       "Candelaria, Colombia             6   6.00\n",
       "Rionegro, Colombia               4   4.00\n",
       "Los Patios, Colombia             4   4.00\n",
       "Bucaramanga, Colombia            4   4.00\n",
       "Santa Marta, Colombia            3   3.00\n",
       "Envigado, Colombia               3   3.00\n",
       "Ibagu, Colombia                 3   3.00\n",
       "Facatativ, Colombia             2   2.00\n",
       "Valledupar, Colombia             2   2.00\n",
       "Valle del Cauca, Colombia        2   2.00\n",
       "Villavicencio, Colombia          2   2.00\n",
       "Riohacha, Colombia               2   2.00\n",
       "Soledad, Colombia                2   2.00\n",
       "Arauca, Colombia                 2   2.00"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cities_top_feb_recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the ratio between official numbers and the migrants found\n",
    "Ratio_feb_Bogota = official_Bogota_22/59\n",
    "Ratio_feb_Medellin = official_Medellin_22/22\n",
    "Ratio_feb_Cucuta = official_Cucuta_22/12\n",
    "Ratio_feb_Candelaria = official_Candelaria_22/6\n",
    "Ratio_feb_Barranquilla = official_Barranquilla_22/6\n",
    "\n",
    "new_Ratios_feb_sliding_recurrent = [Ratio_feb_Bogota, Ratio_feb_Candelaria, Ratio_feb_Medellin, Ratio_feb_Cucuta, Ratio_feb_Barranquilla]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.47429066695038"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficient of variation\n",
    "cv(new_Ratios_feb_sliding_recurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>2477588.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bogot, D.C., Colombia</th>\n",
       "      <td>765328.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medelln, Colombia</th>\n",
       "      <td>285376.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ccuta, Colombia</th>\n",
       "      <td>155659.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cartagena, Colombia</th>\n",
       "      <td>103773.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barranquilla, Colombia</th>\n",
       "      <td>77829.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Candelaria, Colombia</th>\n",
       "      <td>77829.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rionegro, Colombia</th>\n",
       "      <td>51886.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Patios, Colombia</th>\n",
       "      <td>51886.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bucaramanga, Colombia</th>\n",
       "      <td>51886.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Mean\n",
       "Total                  2477588.00\n",
       "Bogot, D.C., Colombia  765328.23\n",
       "Medelln, Colombia      285376.63\n",
       "Ccuta, Colombia        155659.98\n",
       "Cartagena, Colombia     103773.32\n",
       "Barranquilla, Colombia   77829.99\n",
       "Candelaria, Colombia     77829.99\n",
       "Rionegro, Colombia       51886.66\n",
       "Los Patios, Colombia     51886.66\n",
       "Bucaramanga, Colombia    51886.66"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result_df_city_migrants_upscaled_sliding_feb_recurrent.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "Most_Common_df_sliding = pd.DataFrame(Most_Common)\n",
    "\n",
    "Most_Common_df_sliding= Most_Common_df_sliding.T\n",
    "Most_Common_df_sliding.sort_values('Total', ascending=False, inplace=True)\n",
    "Most_Common_df_sliding.to_csv('Most_Common_sliding_recurrent.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = Most_Common_df_sliding.loc['Cali and Calendaria'] = Most_Common_df_sliding.loc['Candelaria, Colombia'] + Most_Common_df_sliding.loc['Cali, Colombia']\n",
    "Most_Common_df_sliding.loc['Cali and Calendaria'] = new_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Most_Common_df_sliding.sort_values('Total', ascending = False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Transpose the DataFrame to have inner dictionaries as rows\n",
    "new_df = Months_df_sliding_recurrent.T\n",
    "\n",
    "# Plotting the DataFrame\n",
    "\n",
    "ax = new_df.plot.line()\n",
    "\n",
    "# Move the legend to the right side\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_title('Migrants in Colombian cities:\\n Sliding window with recurrent migrants')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Number of migrants')\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exclude recurrent migrants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the most commonly chosen cities as places of residence and how many migrants can be detected per month in each city: Excluding recurrent migrants\n",
    "\n",
    "Most_Common_no_recurrent = {}\n",
    "Months_Dicts_no_recurrent = {}\n",
    "for user, value in Migrant_dict_sliding.items():\n",
    "    for k, v in value.items():\n",
    "        if (k != 'Entire_Residence_Period_CO') & (k!= 'Entire_Residence_Period_VE'):\n",
    "        \n",
    "            \n",
    "            \n",
    "            for e, val in v.items():\n",
    "                if e == 'Full_name':\n",
    "                    Place_name= val\n",
    "                if e == 'Place_ID':\n",
    "                    Place_ID = val\n",
    "                    periods = k.split('_')\n",
    "                    if user not in recurrent_sliding:\n",
    "                        if Place_name not in Months_Dicts_no_recurrent:\n",
    "                \n",
    "                            Months_Dicts_no_recurrent[Place_name] = {}\n",
    "                            for year in range(2018, 2023):\n",
    "                                for month in range(1, 13):\n",
    "                                    # Create a key for the month, with leading zeros if necessary (e.g., '2018_01')\n",
    "                                    key = f\"{year}_{month:02d}\"\n",
    "                                    # Assign an initial value of None to the key\n",
    "                                    Months_Dicts_no_recurrent[Place_name][key] = 0\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        start = periods[0]\n",
    "                        end = periods[1]\n",
    "                \n",
    "                        start_month = start[:2]\n",
    "                        start_year = start[2:]\n",
    "                        end_month = end[:2]\n",
    "                        end_year = end[2:]\n",
    "        \n",
    "                        if int(start_month) > int(end_month):\n",
    "                            for year in range(int(start_year), int(end_year) + 1):\n",
    "                                for month in range(int(start_month), 13):\n",
    "                                    if year == int(end_year):\n",
    "                                        continue \n",
    "                                    Occ = f\"{year}_{month:02d}\"\n",
    "                                    for key in Months_Dicts_no_recurrent[Place_name].keys():\n",
    "                                        if Occ == key:\n",
    "                                            Months_Dicts_no_recurrent[Place_name][key] += 1\n",
    "                                        \n",
    "\n",
    "                                for month in range(1, int(end_month) + 1):\n",
    "                                    if year == int(start_year):\n",
    "                                        continue\n",
    "                                    Occ = f\"{year}_{month:02d}\"\n",
    "                                    for key in Months_Dicts_no_recurrent[Place_name].keys():\n",
    "                                        if Occ == key:\n",
    "                                \n",
    "                                            Months_Dicts_no_recurrent[Place_name][key] += 1\n",
    "                                        \n",
    "\n",
    "                        else:\n",
    "                            for year in range(int(start_year), int(end_year) + 1):\n",
    "                                for month in range(int(start_month), int(end_month) + 1):\n",
    "                                    Occ = f\"{year}_{month:02d}\"\n",
    "                                    for key in Months_Dicts_no_recurrent[Place_name].keys():\n",
    "                                        if Occ == key:\n",
    "                                        \n",
    "                                            Months_Dicts_no_recurrent[Place_name][key] += 1\n",
    "                                            \n",
    "\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        if Place_name in Most_Common_no_recurrent:\n",
    "                            Most_Common_no_recurrent[Place_name]['Total'] += 1\n",
    "                        else:\n",
    "                            Most_Common_no_recurrent[Place_name]= {}\n",
    "                            \n",
    "                           \n",
    "                            Most_Common_no_recurrent[Place_name]['Total'] = 1\n",
    "                            Most_Common_no_recurrent[Place_name]['ID'] = Place_ID\n",
    "                   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Most_Common_df_sliding_no_recurrent = pd.DataFrame(Most_Common_no_recurrent)\n",
    "\n",
    "Most_Common_df_sliding_no_recurrent= Most_Common_df_sliding_no_recurrent.T\n",
    "\n",
    "Most_Common_df_sliding_no_recurrent.to_csv('Most_Common_sliding.csv')\n",
    "new_row = Most_Common_df_sliding_no_recurrent.loc['Candelaria, Colombia'] + Most_Common_df_sliding_no_recurrent.loc['Cali, Colombia']\n",
    "Most_Common_df_sliding_no_recurrent.loc['Cali and Calendaria'] = new_row\n",
    "Most_Common_df_sliding_no_recurrent.sort_values('Total', ascending=False, inplace=True)\n",
    "Most_Common_df_sliding_no_recurrent.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and add a 'Total' row which sums up the migrants in CO per month\n",
    "\n",
    "Months_df_sliding_no_recurrent = pd.DataFrame(Months_Dicts_no_recurrent)\n",
    "Months_df_sliding_no_recurrent = Months_df_sliding_no_recurrent.T\n",
    "Months_df_sliding_no_recurrent.loc['Total'] = Months_df_sliding_no_recurrent.sum(axis=0)\n",
    "\n",
    "Months_df_sliding_no_recurrent.to_csv('Months_df_sliding_no_recurrent.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select time periods to analyze: Excluding recurrent migrants\n",
    "\n",
    "months_df_month_22_no_recurrent = Months_df_sliding_no_recurrent.drop(columns=Months_df_sliding_no_recurrent.columns[:48], axis=1)\n",
    "months_df_feb_22_no_recurrent = months_df_month_22_no_recurrent[['2022_02']]\n",
    "Jan_to_March_df_22_no_recurrent = Months_df_sliding_no_recurrent.iloc[:, 48:51]\n",
    "\n",
    "# Add column with average value per city over the time period selected: Excluding recurrent migrants\n",
    "\n",
    "Jan_to_March_df_22_no_recurrent['Mean'] =Jan_to_March_df_22_no_recurrent.mean(axis=1)\n",
    "months_df_month_22_no_recurrent['Mean'] =months_df_month_22_no_recurrent.mean(axis=1)\n",
    "months_df_feb_22_no_recurrent['Mean'] =months_df_feb_22_no_recurrent.mean(axis=1)\n",
    "\n",
    "\n",
    "# Sort values: Excluding recurrent migrants\n",
    "\n",
    "Cities_top_22_no_recurrent = months_df_month_22_no_recurrent.sort_values('Mean', ascending=False).head(10)\n",
    "Cities_top_feb_no_recurrent = months_df_feb_22_no_recurrent.sort_values('Mean', ascending=False).head(10)\n",
    "Cities_top_Jan_to_March_no_recurrent = Jan_to_March_df_22_no_recurrent.sort_values('Mean', ascending=False).head(10)\n",
    "\n",
    "# Upscale the city values according to the ratio of migrants to the number of migrants found per city\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "Result_df_city_migrants_upscaled_sliding_feb_no_recurrent = pd.DataFrame(2477588/Cities_top_feb_no_recurrent.at['Total', 'Mean'] * Cities_top_feb_no_recurrent['Mean'])\n",
    "\n",
    "Result_df_city_migrants_upscaled_sliding_JanMarch_no_reccurent = pd.DataFrame(2477588/Cities_top_Jan_to_March_no_recurrent.at['Total', 'Mean'] * Cities_top_Jan_to_March_no_recurrent['Mean'])\n",
    "\n",
    "Result_df_city_migrants_upscaled_sliding_22_no_recurrent = pd.DataFrame(2477588/Cities_top_22_no_recurrent.at['Total', 'Mean'] * Cities_top_22_no_recurrent['Mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_df_city_migrants_upscaled_sliding_feb_no_recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cities_top_feb_no_recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratio_feb_Cucuta_no = official_Cucuta_22/10\n",
    "Ratio_feb_Bogota_no = official_Bogota_22/39\n",
    "Ratio_feb_Medellin_no = official_Medellin_22/18\n",
    "Ratio_feb_Candelaria_no = official_Candelaria_22/6\n",
    "Ratio_feb_Barranquilla_no = official_Barranquilla_22/5\n",
    "new_Ratios_feb_sliding_no_recurrent = [Ratio_feb_Bogota_no, Ratio_feb_Candelaria_no, Ratio_feb_Medellin_no, Ratio_feb_Cucuta_no, Ratio_feb_Barranquilla_no]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.24216127835395"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(new_Ratios_feb_sliding_no_recurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Transpose the DataFrame to have inner dictionaries as rows\n",
    "new_df = Months_df_sliding_no_recurrent.T\n",
    "\n",
    "# Plotting the DataFrame\n",
    "\n",
    "ax = new_df.plot.line()\n",
    "\n",
    "# Move the legend to the right side\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_title('Migrants in Colombian cities: \\n Sliding window without recurrent migrants')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Number of migrants')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modal Approach**: *Individual Month*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find for each user the country which they tweeted most often from during each month \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    def get_last_day_of_month(input_date):\n",
    "        #input_date needs to be datetime\n",
    "        same_day_next_month = input_date + relativedelta(months=+1)\n",
    "        first_day_next_month = same_day_next_month.replace(day=1)\n",
    "        last_day_current_month = first_day_next_month - timedelta(days=1)\n",
    "        return last_day_current_month\n",
    "\n",
    "    path = \"C:\\\\Users\\\\fabia\\\\OneDrive\"\n",
    "    file = 'All_Tweets_22.csv'\n",
    "    filepath = path + '\\\\'+file\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.rename(columns={'User_ID': 'user', 'Place': 'country', 'Created_At': 'date'}, inplace=True)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['user'] = [str(i) for i in df['user']]\n",
    "    months_dict = {}\n",
    "\n",
    "\n",
    "    all_users = list(df['user'].unique())\n",
    "\n",
    "\n",
    "    months_list = []\n",
    "    # Loop through the years 2018 to 2022 and the months 1 to 12 for each year\n",
    "    for year in range(2018, 2023):\n",
    "        for month in range(1, 13):\n",
    "            # Create a key for the month, with leading zeros if necessary (e.g., '2018_01')\n",
    "            new_month = f\"{year}_{month:02d}\"\n",
    "            # Assign an initial value of None to the key\n",
    "            months_list.append(new_month)\n",
    "\n",
    "   \n",
    "     \n",
    "\n",
    "    tweets_by_country_by_day_dict = {'user':'user0','country':'other',month:1}\n",
    "    df_tweets_by_country_by_day = pd.DataFrame.from_dict(tweets_by_country_by_day_dict,orient='index').reset_index().T\n",
    "    Init = True\n",
    "    for month in months_list:\n",
    "        year_str, month_str = month.split('_')\n",
    "        year_int = int(year_str)\n",
    "        month_int = int(month_str)\n",
    "        timezone = pytz.timezone('UTC')\n",
    "    \n",
    "        now = dt.datetime.now(timezone)\n",
    "        \n",
    "        month_start = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "        month_end = month_start.replace(day=28) + dt.timedelta(days=4)\n",
    "        month_end = month_end - dt.timedelta(days=month_end.day)\n",
    "        \n",
    "        \n",
    "        df_tweets_within_month = df[(df['date'] >= month_start) & (df['date'] <= month_end)].copy()\n",
    "        \n",
    "\n",
    "        #restrict countries: only VE, CO and 'other':\n",
    "        df_tweets_within_month['country'] =  df_tweets_within_month\\\n",
    "            .apply(lambda x: 'other' if (x['country']!='VE')and((x['country']!='CO') ) \\\n",
    "                                else x['country'], axis=1)\n",
    "        \n",
    "        #count the number of tweets by user, by country within window\n",
    "        df_nr_of_tweets_by_user_country_in_month = df_tweets_within_month\\\n",
    "            .groupby(['user', 'country'], as_index=False).size()\n",
    "        \n",
    "        #select for each user the country with the most tweets\n",
    "        df_country_by_user_with_max_tweets_in_month=df_nr_of_tweets_by_user_country_in_month.loc[df_nr_of_tweets_by_user_country_in_month\\\n",
    "                .groupby([\"user\"])[\"size\"].idxmax().values]\n",
    "\n",
    "        #drop size column:\n",
    "        df_country_by_user_with_max_tweets_in_month.drop('size', axis=1, inplace=True)  \n",
    "        \n",
    "        #add column with selected day and set value to 1\n",
    "        current_date_str = month\n",
    "        df_country_by_user_with_max_tweets_in_month[current_date_str] = 1\n",
    "\n",
    "        print(\"Now processing:\",current_date_str)\n",
    "\n",
    "        #add rows with other countries but value = 0\n",
    "        df_to_dict = df_country_by_user_with_max_tweets_in_month.to_dict('records')\n",
    "        for row in df_to_dict:\n",
    "            if row['country']=='VE':\n",
    "                df_country_by_user_with_max_tweets_in_month=\\\n",
    "                pd.concat([df_country_by_user_with_max_tweets_in_month,\\\n",
    "                        pd.DataFrame([{'user':row['user'],'country':'CO',current_date_str:0}])])\n",
    "                df_country_by_user_with_max_tweets_in_month=\\\n",
    "                pd.concat([df_country_by_user_with_max_tweets_in_month,\\\n",
    "                        pd.DataFrame([{'user':row['user'],'country':'other',current_date_str:0}])],ignore_index=True)\n",
    "            elif row['country']=='CO':\n",
    "                df_country_by_user_with_max_tweets_in_month=\\\n",
    "                pd.concat([df_country_by_user_with_max_tweets_in_month,\\\n",
    "                        pd.DataFrame([{'user':row['user'],'country':'VE',current_date_str:0}])],ignore_index=True)\n",
    "                df_country_by_user_with_max_tweets_in_month=\\\n",
    "                pd.concat([df_country_by_user_with_max_tweets_in_month,\\\n",
    "                        pd.DataFrame([{'user':row['user'],'country':'other',current_date_str:0}])],ignore_index=True)\n",
    "            elif row['country']=='other':\n",
    "                df_country_by_user_with_max_tweets_in_month=\\\n",
    "                pd.concat([df_country_by_user_with_max_tweets_in_month,\\\n",
    "                        pd.DataFrame([{'user':row['user'],'country':'VE',current_date_str:0}])],ignore_index=True)\n",
    "                df_country_by_user_with_max_tweets_in_month=\\\n",
    "                pd.concat([df_country_by_user_with_max_tweets_in_month,\\\n",
    "                        pd.DataFrame([{'user':row['user'],'country':'CO',current_date_str:0}])],ignore_index=True)\n",
    "            else:\n",
    "                print(\"ERROR: unexpected country\",row)\n",
    "\n",
    "\n",
    "\n",
    "        # add all other users not in window to df with value 0 for all countries VE,CO,'other'\n",
    "        users_in_window = list(df_country_by_user_with_max_tweets_in_month['user'].unique())\n",
    "        users_not_in_window = [u for u in all_users if u not in users_in_window]\n",
    "        users_not_in_window_dict = {}\n",
    "        for u in users_not_in_window:\n",
    "                df_country_by_user_with_max_tweets_in_month=\\\n",
    "                pd.concat([df_country_by_user_with_max_tweets_in_month,\\\n",
    "                        pd.DataFrame([{'user':u,'country':'VE',current_date_str:0}])],ignore_index=True)\n",
    "                df_country_by_user_with_max_tweets_in_month=\\\n",
    "                pd.concat([df_country_by_user_with_max_tweets_in_month,\\\n",
    "                        pd.DataFrame([{'user':u,'country':'CO',current_date_str:0}])],ignore_index=True)\n",
    "                df_country_by_user_with_max_tweets_in_month=\\\n",
    "                pd.concat([df_country_by_user_with_max_tweets_in_month,\\\n",
    "                        pd.DataFrame([{'user':u,'country':'other',current_date_str:0}])],ignore_index=True)\n",
    "        \n",
    "\n",
    "\n",
    "        df_result = df_country_by_user_with_max_tweets_in_month\n",
    "\n",
    "        #need a unique key to join and #type conversion from float /int to str\n",
    "        #df_result['key'] = df_result.apply(lambda x: str(x['user'])+'_'+str(x['country']),axis=1 )\n",
    "        df_result[current_date_str]=df_result[month].astype(str) \n",
    "        \n",
    "        # at beginning  df_overall_result is equal df_result\n",
    "        if Init:\n",
    "            df_overall_result = df_result.copy()\n",
    "            Init = False\n",
    "        else:\n",
    "            #remove columns not needed for join:\n",
    "            # df_result.drop('user', axis=1, inplace=True) \n",
    "            # df_result.drop('country', axis=1, inplace=True) \n",
    "            df_overall_result = pd.merge(df_overall_result,df_result,on=['user','country'])\n",
    "            \n",
    "\n",
    "        \n",
    "       \n",
    "    \n",
    "    df_overall_result.to_csv('overall_result_byMonth.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all residents, meaning users who tweeted most frequently from the same country over a three month period\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "debug_mode = False\n",
    "limit_data = False #restrict the processing to 200 users: works only if debug_mode == False\n",
    "short_cut = True # last two month always 'in_transit'\n",
    "\n",
    "if debug_mode:\n",
    "    print(\"INFO: debug mode is activated. Only selected user will be processed. \")\n",
    "if limit_data:\n",
    "    print(\"INFO: limited output data: only 200 users will be processed. \")\n",
    "if short_cut:\n",
    "    print(\"INFO: short cut: last two month will be set to 'in_transit'\")\n",
    "path = \"C:\\\\Users\\\\fabia\\\\OneDrive\\\\\"\n",
    "inputfile = 'new_overall_result_bymonth.csv'\n",
    "\n",
    "\n",
    "outputfile = 'resident_user_by_country_by_month_in_cols_month.csv' #if user is not resident, he will be assigned to 'in_transit' country\n",
    "filepath = path + '\\\\'+inputfile\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['user'] = [str(i) for i in df['user']]\n",
    "df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "\n",
    "user_residence_periods_dict = {} \n",
    "\n",
    "\n",
    "\n",
    "list_of_cols = df.columns.to_list() #first col: user, second col: country, third and following cols: month\n",
    "nr_of_month = len(list_of_cols)- 2 #nr of month is all columns excluding user and country\n",
    "empty_in_transit_dict = {}\n",
    "empty_no_data_dict = {}\n",
    "\n",
    "if short_cut:\n",
    "    #### SHORTCUT: initialize to 0, but only up to col n-2 und n-1, above everything is 'in_transit'\n",
    "    for i in range(nr_of_month-2):\n",
    "        empty_in_transit_dict.update({list_of_cols[i+2]:0})\n",
    "        empty_no_data_dict.update({list_of_cols[i+2]:0})\n",
    "\n",
    "    #### SHORTCUT: put everything in col n-2 und n-1 to 'in_transit' \n",
    "    for i in range(nr_of_month-2,nr_of_month):\n",
    "        empty_in_transit_dict.update({list_of_cols[i+2]:1})\n",
    "        empty_no_data_dict.update({list_of_cols[i+2]:0})\n",
    "else:\n",
    "    for i in range(nr_of_month):\n",
    "        empty_in_transit_dict.update({list_of_cols[i+2]:0})\n",
    "        empty_no_data_dict.update({list_of_cols[i+2]:0})\n",
    "        \n",
    "\n",
    "all_users = df['user'].unique()\n",
    "resident_country_list = []\n",
    "\n",
    "counter = 0\n",
    "for u in all_users:\n",
    "    ##### LIMIT OUTPUT DATA ##############\n",
    "    if not debug_mode:\n",
    "        if limit_data:\n",
    "            counter += 1\n",
    "            if counter >200:\n",
    "                break\n",
    "    ##### END OF LIMIT OUTPUT DATA  ##############\n",
    "\n",
    "    #to track number of residence countries and length of resident periods:\n",
    "    first_residence_country_found = False\n",
    "    start_period = None\n",
    "    duration = None\n",
    "\n",
    "\n",
    "    #select one user with all his countries:\n",
    "    df_user = df[df['user']== u].copy()\n",
    "    df_user_list_of_dict = df_user.to_dict('records')\n",
    "\n",
    "\n",
    "    ##### DEBUG ##############\n",
    "    if debug_mode:\n",
    "        if u != '100101191': ###JUST TO SELECT ONE USER FOR TESTING/DEBUGGING \n",
    "\n",
    "                continue\n",
    "        else:\n",
    "            df1 = pd.DataFrame(df_user_list_of_dict)\n",
    "            df1.to_csv(\"check_user.csv\")\n",
    "    ##### END OF DEBUG ##############\n",
    "\n",
    "    #### SHORTCUT: put everything in col n-2 und n-1 to 'in_transit', therefore set all countries in n-2, n-1 to 0' \n",
    "    if short_cut:\n",
    "        for i in df_user_list_of_dict: #set all real countrys to 0\n",
    "                i[list_of_cols[-2]] = 0\n",
    "                i[list_of_cols[-1]] = 0\n",
    "\n",
    "    print(u)\n",
    "    col_pointer = 2 #points to the first month col in a triple of cols\n",
    "\n",
    "    #initialize col names:\n",
    "\n",
    "\n",
    "\n",
    "    in_transit_dict = {'user':u,'country':'in_transit'}\n",
    "    in_transit_dict.update(empty_in_transit_dict)\n",
    "    no_data_dict = {'user': u, 'country': 'no data'}\n",
    "    no_data_dict.update(empty_no_data_dict)\n",
    "\n",
    "    df_user_list_of_dict.append(in_transit_dict)\n",
    "    df_user_list_of_dict.append(no_data_dict)\n",
    "\n",
    "    sliding_window_nr_of_cols = 3\n",
    "    first_month = 2 # position of col for first month \n",
    "    nr_of_consecutive_cols_to_find = sliding_window_nr_of_cols #nr_of_consecutive_cols_to_find changes dynamically but starts with sliding window size\n",
    "\n",
    "    while col_pointer+sliding_window_nr_of_cols <= nr_of_month +first_month : # 2 is offset for first_columns\n",
    "        col_list = list_of_cols[col_pointer:col_pointer+nr_of_consecutive_cols_to_find]\n",
    "        ##### DEBUG ##############\n",
    "        # if debug_mode:\n",
    "        #     if col_list[0] == '102018':\n",
    "        #         print('breakpoint')\n",
    "        ##### END OF DEBUG ##############\n",
    "        \n",
    "        #len_of_col_list three consecutives cols starting from pointer\n",
    "\n",
    "        df_user_window = df_user[['country']+col_list]\n",
    "\n",
    "        res_dict = df_user_window[df_user_window[col_list].sum(axis=1)==nr_of_consecutive_cols_to_find].to_dict('records') # e.g. three consecutive cols needs to be 3 to be residents       \n",
    "        \n",
    "        if len(res_dict)>0: # new potential resident country has been found, no_data is False otherwise res_dict would be 0 \n",
    "            # more precisely: in selected col_list, there is one country with nr_of_consecutive_cols_to_find,\n",
    "            # if step = 1 it could still be in_transit \n",
    "            # remark: if len(col_list) == 1, this condition is always true except if no_data\n",
    "            new_resident_country = res_dict[0]['country']\n",
    "            if nr_of_consecutive_cols_to_find < sliding_window_nr_of_cols: # it true it is 1-step only\n",
    "                if not (new_resident_country == resident_country):  #it true it's change of country and 1  step\n",
    "                    # if true the new country does not equal existing resident country and is a change in country\n",
    "                    # because it was only 1 step, it can be checked if the new_resident country is again a new real resident country,\n",
    "                    # this check requires to look at all cols in the sliding_window_nr_of_cols\n",
    "                    # if this check fails, the new resident country will be in transit, no_data is not possible\n",
    "                    col_list = list_of_cols[col_pointer:col_pointer+sliding_window_nr_of_cols] #check all columns in sliding_window_nr_of_cols\n",
    "                    df_user_window = df_user[['country']+col_list]\n",
    "\n",
    "\n",
    "                    res_dict = df_user_window[df_user_window[col_list].sum(axis=1)==sliding_window_nr_of_cols].to_dict('records') # e.g. three consecutive cols needs to be 3 to be residents       \n",
    "                    if len(res_dict)>0: #if true a new resident country has been found\n",
    "                        #track resident periods per users:\n",
    "                        if not first_residence_country_found: #this is the first residence country\n",
    "                            first_residence_country_found = True\n",
    "                            start_period = list_of_cols[col_pointer]\n",
    "                            duration = col_pointer\n",
    "                        else: #store previous residence country\n",
    "                            resident_country_list.extend([{'user':u,'residence_country':resident_country,'start_period':start_period,'duration':col_pointer - duration}])\n",
    "                            start_period = list_of_cols[col_pointer]\n",
    "                            duration = col_pointer\n",
    "                        resident_country = new_resident_country\n",
    "                        col_pointer+=sliding_window_nr_of_cols\n",
    "                        nr_of_consecutive_cols_to_find = 1\n",
    "                        # col_pointer is moved sliding_window_nr_of_cols \n",
    "                        # and search modus is 1-step\n",
    "\n",
    "\n",
    "                    else: #no real new resident country found\n",
    "                        # meaning the new resident country will become in transit, because no_data is not an option:\n",
    "                        # the column in this 1 step cannot be 'no_data', because length of of initial res_dict > 0\n",
    "                        if not first_residence_country_found: #this is the first residence country\n",
    "                                    first_residence_country_found = True\n",
    "                                    start_period = list_of_cols[col_pointer]\n",
    "                                    duration = col_pointer\n",
    "                        else: #store previous residence country\n",
    "                                    resident_country_list.extend([{'user':u,'residence_country':resident_country,'start_period':start_period,'duration':col_pointer - duration}])\n",
    "                                    start_period = list_of_cols[col_pointer]\n",
    "                                    duration = col_pointer \n",
    "\n",
    "                        #double check if there is really data:\n",
    "                        if df_user_window[list_of_cols[col_pointer]].values.sum() == 0:\n",
    "                                print(\"ERROR: expected data, but found no_data.\")\n",
    "                                print(df_user_list_of_dict)     \n",
    "\n",
    "                        for i in df_user_list_of_dict: #set all real countrys to 0\n",
    "                            i[list_of_cols[col_pointer]] = 0\n",
    "                        df_user_list_of_dict[-2][list_of_cols[col_pointer]] = 1 # set in_transit to 1\n",
    "                        resident_country = 'in_transit'\n",
    "                        # nr of cols for next resident country is full sice of sliding_window_nr_of_cols\n",
    "                        nr_of_consecutive_cols_to_find = sliding_window_nr_of_cols\n",
    "                        #shift window one month to the next col:\n",
    "                        col_pointer += 1\n",
    "\n",
    "                        #process end of data / last columns:\n",
    "                else: #the new_resident_country is the same as the already existing resident_country\n",
    "                    nr_of_consecutive_cols_to_find = 1  # in next loop check only the next col to see if 1 consecutive country is in it \n",
    "                    col_pointer += 1   \n",
    "            else: #len of col_list is 3, these 3 cols have been analysed and a new resident country has been found \n",
    "                #track resident periods per users:\n",
    "                if not first_residence_country_found: #this is the first residence country\n",
    "                            first_residence_country_found = True\n",
    "                            start_period = list_of_cols[col_pointer]\n",
    "                            duration = col_pointer\n",
    "                else: #store previous residence country\n",
    "                            resident_country_list.extend([{'user':u,'residence_country':resident_country,'start_period':start_period,'duration':col_pointer - duration}])\n",
    "                            start_period = list_of_cols[col_pointer]\n",
    "                            duration = col_pointer                            \n",
    "                \n",
    "                resident_country = new_resident_country\n",
    "                nr_of_consecutive_cols_to_find = 1 #single steps until change in country\n",
    "                col_pointer += sliding_window_nr_of_cols   #start next loop beyond these 3 cols belonging to new resident country\n",
    "\n",
    "        else: #no potential resident_country found: column needs to be set either to in_transit or to no_data\n",
    "            # to check if there was no data  all values are summarized across df and col_list: \n",
    "            # formula: df_user_window[list_of_cols[col_pointer]].values.sum()\n",
    "            # values only for the column at col_pointer\n",
    "            # exception: if col == first_col, it should be treated as resident\n",
    "\n",
    "            #track resident periods per users:\n",
    "            if not first_residence_country_found: #this is the first residence country\n",
    "                        first_residence_country_found = True\n",
    "                        start_period = list_of_cols[col_pointer]\n",
    "                        duration = col_pointer\n",
    "            else: #store previous residence country\n",
    "                        resident_country_list.extend([{'user':u,'residence_country':resident_country,'start_period':start_period,'duration':col_pointer - duration}])\n",
    "                        start_period = list_of_cols[col_pointer]\n",
    "                        duration = col_pointer        \n",
    "\n",
    "            for i in df_user_list_of_dict: #set all real countrys to 0\n",
    "                    i[list_of_cols[col_pointer]] = 0\n",
    "\n",
    "            if df_user_window[list_of_cols[col_pointer]].values.sum() >0: #if true, col is in_transit, if otherwise no_data\n",
    "                resident_country = 'in_transit'\n",
    "                df_user_list_of_dict[-2][list_of_cols[col_pointer]] = 1 # set in transit to 1\n",
    "            else:\n",
    "                resident_country = 'no_data'\n",
    "                df_user_list_of_dict[-1][list_of_cols[col_pointer]] = 1 \n",
    "\n",
    "\n",
    "            nr_of_consecutive_cols_to_find = sliding_window_nr_of_cols\n",
    "            # next loop only 1 column shift:\n",
    "            col_pointer += 1\n",
    "            if col_pointer+sliding_window_nr_of_cols > nr_of_month+2: #exception processing for the last two columns\n",
    "                # df2 = pd.DataFrame(df_user_list_of_dict)\n",
    "                # df2.to_excel(\"check_user_output.xlsx\")\n",
    "                break\n",
    "                for new_col_pointer in range(col_pointer, len(df_user_list_of_dict[1])):\n",
    "                    count_zero = 0\n",
    "                    for i in df_user_list_of_dict:\n",
    "                        count = i[list_of_cols[new_col_pointer]]\n",
    "                        count_zero += count\n",
    "                    if count_zero == 0:\n",
    "                        for i in df_user_list_of_dict:\n",
    "                \n",
    "                            i[list_of_cols[new_col_pointer]] = 0\n",
    "                    \n",
    "                        df_user_list_of_dict[-1][list_of_cols[new_col_pointer]] = 1 \n",
    "                        resident_country = 'no_data'\n",
    "                    else:\n",
    "\n",
    "                        for i in df_user_list_of_dict:\n",
    "                            i[list_of_cols[new_col_pointer]] = 0\n",
    "                        df_user_list_of_dict[-2][list_of_cols[new_col_pointer]] = 1\n",
    "                        resident_country = 'in_transit'\n",
    "\n",
    "    if first_residence_country_found: \n",
    "        #store last residence country\n",
    "            resident_country_list.extend([{'user':u,'residence_country':resident_country,'start_period':start_period,'duration':col_pointer - duration}])\n",
    "                                    \n",
    "    user_residence_periods_dict[u] = resident_country_list\n",
    "    df_result = pd.concat([df_result,pd.DataFrame(df_user_list_of_dict)],ignore_index=True)     \n",
    "        \n",
    "df_user_residence_periods = pd.DataFrame(resident_country_list)\n",
    "df_user_residence_periods.to_csv(\"user_residence_periods.csv\")\n",
    "df_result.to_csv(outputfile)\n",
    "\n",
    "print('Done') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "Residents = pd.read_csv('no_end_residents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Residents_VE = Residents[Residents.country == 'VE']\n",
    "Residents_other = Residents[Residents.country == 'other']\n",
    "Residents_CO = Residents[Residents.country == 'CO']\n",
    "Residents_transit = Residents[Residents.country == 'in_transit']\n",
    "Residents_data = Residents[Residents.country == 'no data']\n",
    "\n",
    "Residents_data = Residents_data.replace({0: 1, 1: 0})\n",
    "\n",
    "count_VE= Residents_VE.iloc[:, 6:-3].sum()/Residents_data.iloc[:, 6:-3].sum()*100\n",
    "count = Residents_CO.iloc[:, 6:-3].sum()/Residents_data.iloc[:, 6:-3].sum()*100\n",
    "count_other = Residents_other.iloc[:, 6:-3].sum()/Residents_data.iloc[:, 6:-3].sum()*100\n",
    "count_all = Residents_data.iloc[:, 6:-3].sum()\n",
    "count_transit = Residents_transit.iloc[:, 6:-3].sum()/Residents_data.iloc[:, 3:].sum()*100\n",
    "\n",
    "\n",
    "plt.plot(count.index, count.values, color = 'blue', label='Residents in Colombia')\n",
    "plt.plot(count_VE.index, count_VE.values, color='red', label='Residents in Venezuela')\n",
    "plt.plot(count_other.index, count_other.values, color='green', label='Resdients globally')\n",
    "#plt.plot(count_all.index, count_all.values, color='black', label='All Users')\n",
    "plt.plot(count_transit.index, count_transit.values, color='purple', label='Users in transit')\n",
    "\n",
    "plt.xticks(count.index[::3], count.index[::3], rotation=90)\n",
    "plt.xticks()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Percentage of active users')\n",
    "plt.title('Percentage of users as residents: Individual month')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig('Monthly_Residents_byMonth.png')\n",
    "\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "Users = [int(i) for i in Users ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_tweets.User_ID = [int(i) for i in All_tweets.User_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ve_Residents = []\n",
    "CO_Residents = []\n",
    "Migrant_dict = {}\n",
    "recurrent_bymonth = []\n",
    "timezone = pytz.timezone('UTC')\n",
    "Ratios_byMonth = []\n",
    "\n",
    "now = dt.datetime.now(timezone)\n",
    "\n",
    "for u in Users:\n",
    "  \n",
    "    User_df = Residents[Residents.user == u].copy()\n",
    "    VE = User_df[User_df.country == 'VE']\n",
    "    CO = User_df[User_df.country == 'CO']\n",
    "    if VE.iloc[:,3:].sum().sum() != 0:\n",
    "        Ve_Residents.append(u)\n",
    "       \n",
    "\n",
    "        if CO.iloc[:,3:].sum().sum()!=0:\n",
    "            CO_Residents.append(u)\n",
    "  \n",
    "            user_id = str(u)\n",
    "            Migrant_dict[user_id]={}\n",
    "            Migrant_dict[user_id]['Entire_Residence_Period_CO']= pd.Timedelta(0)\n",
    "            Migrant_dict[user_id]['Entire_Residence_Period_VE']= pd.Timedelta(0)\n",
    "            sequences = CO.iloc[:,3:].apply(lambda row: get_sequences(row), axis=1)\n",
    "            sequences_VE = VE.iloc[:,3:].apply(lambda row: get_sequences(row), axis=1)\n",
    "            \n",
    "            for index, row_sequences in sequences.items():\n",
    "         \n",
    "                for i, (start, end) in enumerate(row_sequences):\n",
    "                   \n",
    "                    year_str, month_str = start.split('_')\n",
    "                    year_int = int(year_str)\n",
    "                    month_int = int(month_str)\n",
    "\n",
    "                    year_int = int(year_str)\n",
    "                    month_int = int(month_str)\n",
    "                    period_start = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                    year_str, month_str = end.split('_')\n",
    "                    year_int = int(year_str)\n",
    "                    month_int = int(month_str)\n",
    "                    if i == 0:\n",
    "                        first_start_CO = period_start\n",
    "\n",
    "                    period_end = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                    period_end = period_end.replace(day=28) + dt.timedelta(days=4)\n",
    "                    period_end = period_end - dt.timedelta(days=period_end.day)\n",
    "                    Tweet_df = All_tweets[All_tweets.User_ID == u].copy()\n",
    "                    Tweet_df_in_residence_period = Tweet_df[(Tweet_df['Created_At'] >= period_start) & (Tweet_df['Created_At'] <= period_end) & (Tweet_df['Place'] == 'CO')].copy()\n",
    "                    valid_row = {}                          \n",
    "                    Tweet_df_in_residence_period.apply(process_tweet, axis=1, args=(valid_row,))\n",
    "                    Diff = period_end-period_start\n",
    "                    Migrant_dict[user_id]['Entire_Residence_Period_CO'] += Diff\n",
    "                    \n",
    "                    # Find the dictionary with the highest Occurence value in valid_row\n",
    "                    Max_Duration = max(valid_row.values(), key=lambda x: x['Occurence'])\n",
    "                    Exact_Loc = Max_Duration\n",
    "                    period = f'{start}/{end}'\n",
    "                    # Add Exact_Loc to Migrant_dict\n",
    "                    Migrant_dict[user_id][period] = Exact_Loc\n",
    "                    \n",
    "            for index, row_sequences in sequences_VE.items():\n",
    "                    for i, (start, end) in enumerate(row_sequences):\n",
    "                    \n",
    "                        year_str, month_str = start.split('_')\n",
    "                        year_int = int(year_str)\n",
    "                        month_int = int(month_str)\n",
    "\n",
    "                        year_int = int(year_str)\n",
    "                        month_int = int(month_str)\n",
    "                        period_start = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                        year_str, month_str = end.split('_')\n",
    "                        year_int = int(year_str)\n",
    "                        month_int = int(month_str)\n",
    "\n",
    "                        period_end = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                        period_end = period_end.replace(day=28) + dt.timedelta(days=4)\n",
    "                        period_end = period_end - dt.timedelta(days=period_end.day)\n",
    "                       \n",
    "                        if period_start > first_start_CO:\n",
    "                            Diff_VE = period_end - period_start\n",
    "                            Migrant_dict[user_id]['Entire_Residence_Period_VE'] += Diff_VE\n",
    "                        if i == 0:\n",
    "                            first_start_VE = period_start\n",
    "                            first_end_VE = period_end\n",
    "\n",
    "            try: \n",
    "                Total =  Migrant_dict[user_id]['Entire_Residence_Period_CO'] + Migrant_dict[user_id]['Entire_Residence_Period_VE']         \n",
    "                Ratio =  Migrant_dict[user_id]['Entire_Residence_Period_CO'] / Total\n",
    "                Ratios_byMonth.append(Ratio)\n",
    "                if Ratio < 0.5:\n",
    "                    recurrent_bymonth.append(u)\n",
    "            except:\n",
    "                print('Not recurrent')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1868\n",
      "248\n"
     ]
    }
   ],
   "source": [
    "print(len(Ve_Residents))\n",
    "print(len(CO_Residents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recurrent_bymonth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Ratios_byMonth\n",
    "\n",
    "\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=20)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Ratio')\n",
    "plt.ylabel('Users')\n",
    "plt.title('Distribution of ratios: Individual month model')\n",
    "plt.savefig('Ratios_modal_ByMonth.png')\n",
    "# Display the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_bymonth = [str(i) for i in recurrent_bymonth]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_tweets.User_ID = [str(i) for i in All_tweets.User_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Most_Common_byMonth = {}\n",
    "Months_Dicts_byMonth_recurrent = {}\n",
    "for user, value in Migrant_dict.items():\n",
    "    for k, v in value.items():\n",
    "        if (k != 'Entire_Residence_Period_CO') & (k != 'Entire_Residence_Period_VE') :\n",
    "        \n",
    "            \n",
    "            \n",
    "            for e, val in v.items():\n",
    "            \n",
    "                if e == 'Full_name':\n",
    "                    Place_name= val\n",
    "                if e == 'Place_ID':\n",
    "                    Place_ID = val\n",
    "                    periods = k.split('/')\n",
    "                    if Place_name not in Months_Dicts_byMonth_recurrent:\n",
    "                        Months_Dicts_byMonth_recurrent[Place_name] = {}\n",
    "                        for year in range(2018, 2023):\n",
    "                            for month in range(1, 13):\n",
    "                                # Create a key for the month, with leading zeros if necessary (e.g., '2018_01')\n",
    "                                key = f\"{year}_{month:02d}\"\n",
    "                                # Assign an initial value of None to the key\n",
    "                                Months_Dicts_byMonth_recurrent[Place_name][key] = 0\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    start = periods[0]\n",
    "                    end = periods[1]\n",
    "                    start_month = start[5:]\n",
    "                    start_year = start[:4]\n",
    "                    end_month = end[5:]\n",
    "                    end_year = end[2:]\n",
    "                    if int(start_month) > int(end_month):\n",
    "                        for year in range(int(start_year), int(end_year) + 1):\n",
    "                            for month in range(int(start_month), 13):\n",
    "                                if year == int(end_year):\n",
    "                                    continue \n",
    "                                Occ = f\"{year}_{month:02d}\"\n",
    "                                for key in Months_Dicts_byMonth_recurrent[Place_name].keys():\n",
    "                                    if Occ == key:\n",
    "                                        Months_Dicts_byMonth_recurrent[Place_name][key] += 1\n",
    "\n",
    "                            for month in range(1, int(end_month) + 1):\n",
    "                                if year == int(start_year):\n",
    "                                    continue\n",
    "                                Occ = f\"{year}_{month:02d}\"\n",
    "                                for key in Months_Dicts_byMonth_recurrent[Place_name].keys():\n",
    "                                    if Occ == key:\n",
    "                                        Months_Dicts_byMonth_recurrent[Place_name][key] += 1\n",
    "\n",
    "                    else:\n",
    "                        for year in range(int(start_year), int(end_year) + 1):\n",
    "                            for month in range(int(start_month), int(end_month) + 1):\n",
    "                                Occ = f\"{year}_{month:02d}\"\n",
    "                                for key in Months_Dicts_byMonth_recurrent[Place_name].keys():\n",
    "                                    if Occ == key:\n",
    "                                        Months_Dicts_byMonth_recurrent[Place_name][key] += 1\n",
    "\n",
    "                    if Place_name in Most_Common_byMonth:\n",
    "                        Most_Common_byMonth[Place_name]['Total'] += 1\n",
    "                    else:\n",
    "                        Most_Common_byMonth[Place_name]= {}\n",
    "                    \n",
    "                        Most_Common_byMonth[Place_name]['Others'] = 0\n",
    "                        Most_Common_byMonth[Place_name]['Recurrent'] = 0\n",
    "                        Most_Common_byMonth[Place_name]['Total'] = 1\n",
    "                        Most_Common_byMonth[Place_name]['ID'] = Place_ID\n",
    "                    \n",
    "                    if user in recurrent_bymonth:\n",
    "                        \n",
    "                        Most_Common_byMonth[Place_name]['Recurrent'] += 1\n",
    "        \n",
    "\n",
    "                    else:\n",
    "                        Most_Common_byMonth[Place_name]['Others'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Most_Common_df_month_recurrent = pd.DataFrame(Most_Common_byMonth)\n",
    "\n",
    "Most_Common_df_month_recurrent= Most_Common_df_month_recurrent.T\n",
    "Most_Common_df_month_recurrent.sort_values('Total', ascending=False, inplace=True)\n",
    "Most_Common_df_month_recurrent.to_csv('Most_Common_byMonth.csv')\n",
    "Most_Common_df_month_recurrent.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and add a 'Total' row which sums up the migrants in CO per month\n",
    "\n",
    "Months_df_month = pd.DataFrame(Months_Dicts_byMonth_recurrent)\n",
    "Months_df_month = Months_df_month.T\n",
    "Months_df_month.loc['Total'] = Months_df_month.sum(axis=0)\n",
    "\n",
    "Months_df_month.to_csv('Months_df_byMonth.csv')\n",
    "\n",
    "# Select time periods to analyze: Inluding recurrent\n",
    "\n",
    "months_df_month_22_recurrent = Months_df_month.drop(columns=Months_df_month.columns[:48], axis=1)\n",
    "months_df_feb_22_recurrent = months_df_month_22_recurrent[['2022_02']]\n",
    "Jan_to_March_df_22_recurrent = Months_df_month.iloc[:, 48:51]\n",
    "\n",
    "# Add column with average value per city over the time period selected: Including recurrent\n",
    "\n",
    "Jan_to_March_df_22_recurrent['Mean'] =Jan_to_March_df_22_recurrent.mean(axis=1)\n",
    "months_df_month_22_recurrent['Mean'] =months_df_month_22_recurrent.mean(axis=1)\n",
    "months_df_feb_22_recurrent['Mean'] =months_df_feb_22_recurrent.mean(axis=1)\n",
    "\n",
    "\n",
    "# Sort values: Including recurrent\n",
    "\n",
    "Cities_top_22_recurrent = months_df_month_22_recurrent.sort_values('Mean', ascending=False).head(10)\n",
    "Cities_top_feb_recurrent = months_df_feb_22_recurrent.sort_values('Mean', ascending=False).head(20)\n",
    "Cities_top_Jan_to_March_recurrent = Jan_to_March_df_22_recurrent.sort_values('Mean', ascending=False).head(35)\n",
    "\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "Result_df_city_migrants_upscaled_month_feb_recurrent = pd.DataFrame(2477588/Cities_top_feb_recurrent.at['Total', 'Mean'] * Cities_top_feb_recurrent['Mean'])\n",
    "\n",
    "Result_df_city_migrants_upscaled_month_JanMarch_reccurent = pd.DataFrame(2477588/Cities_top_Jan_to_March_recurrent.at['Total', 'Mean'] * Cities_top_Jan_to_March_recurrent['Mean'])\n",
    "\n",
    "Result_df_city_migrants_upscaled_month_22_recurrent = pd.DataFrame(2477588/Cities_top_22_recurrent.at['Total', 'Mean'] * Cities_top_22_recurrent['Mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cities_top_feb_recurrent['Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratio_feb_Bogota_month =  495236/35\n",
    "Ratio_feb_Barranquilla_month = official_Barranquilla_22/1\n",
    "Ratio_feb_Cucuta_month = 167678/6\n",
    "Ratio_feb_Medellin_month = 190854/14\n",
    "Ratio_feb_Candelaria_month = 121837/4\n",
    "new_Ratios_feb_month_recurrent = [Ratio_feb_Bogota_month, Ratio_feb_Candelaria_month,Ratio_feb_Barranquilla_month,Ratio_feb_Cucuta_month, Ratio_feb_Medellin_month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104.41191368670681"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(new_Ratios_feb_month_recurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_df_city_migrants_upscaled_month_feb_recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_bymonth = [str(i) for i in recurrent_bymonth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Most_Common_byMonth = {}\n",
    "Months_Dicts_byMonth_no_recurrent = {}\n",
    "for user, value in Migrant_dict.items():\n",
    "    for k, v in value.items():\n",
    "        if (k != 'Entire_Residence_Period_VE') &  (k != 'Entire_Residence_Period_CO'):\n",
    "        \n",
    "            \n",
    "            \n",
    "            for e, val in v.items():\n",
    "            \n",
    "                if e == 'Full_name':\n",
    "                    Place_name= val\n",
    "                if e == 'Place_ID':\n",
    "                    Place_ID = val\n",
    "                    periods = k.split('/')\n",
    "                    print(periods[0])\n",
    "                    if user not in recurrent_bymonth:\n",
    "                        if Place_name not in Months_Dicts_byMonth_no_recurrent:\n",
    "\n",
    "                            Months_Dicts_byMonth_no_recurrent[Place_name] = {}\n",
    "                            for year in range(2018, 2023):\n",
    "                                for month in range(1, 13):\n",
    "                                    # Create a key for the month, with leading zeros if necessary (e.g., '2018_01')\n",
    "                                    key = f\"{year}_{month:02d}\"\n",
    "                                    # Assign an initial value of None to the key\n",
    "                                    Months_Dicts_byMonth_no_recurrent[Place_name][key] = 0\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        start = periods[0]\n",
    "                        end = periods[1]\n",
    "                        print('Filling of dict initiated')\n",
    "                        start_month = start[5:]\n",
    "                        start_year = start[:4]\n",
    "                        end_month = end[5:]\n",
    "                        end_year = end[2:]\n",
    "                        print('Start_month', start_month)\n",
    "                        print('End_month', end_month)\n",
    "                        if int(start_month) > int(end_month):\n",
    "                            for year in range(int(start_year), int(end_year) + 1):\n",
    "                                for month in range(int(start_month), 13):\n",
    "                                    if year == int(end_year):\n",
    "                                        continue \n",
    "                                    Occ = f\"{year}_{month:02d}\"\n",
    "                                    for key in Months_Dicts_byMonth_no_recurrent[Place_name].keys():\n",
    "                                        if Occ == key:\n",
    "                                            Months_Dicts_byMonth_no_recurrent[Place_name][key] += 1\n",
    "\n",
    "                                for month in range(1, int(end_month) + 1):\n",
    "                                    if year == int(start_year):\n",
    "                                        continue\n",
    "                                    Occ = f\"{year}_{month:02d}\"\n",
    "                                    for key in Months_Dicts_byMonth_no_recurrent[Place_name].keys():\n",
    "                                        if Occ == key:\n",
    "                                            Months_Dicts_byMonth_no_recurrent[Place_name][key] += 1\n",
    "\n",
    "                        else:\n",
    "                            for year in range(int(start_year), int(end_year) + 1):\n",
    "                                for month in range(int(start_month), int(end_month) + 1):\n",
    "                                    Occ = f\"{year}_{month:02d}\"\n",
    "                                    for key in Months_Dicts_byMonth_no_recurrent[Place_name].keys():\n",
    "                                        if Occ == key:\n",
    "                                            print(Occ)\n",
    "                                            Months_Dicts_byMonth_no_recurrent[Place_name][key] += 1\n",
    "\n",
    "                        if Place_name in Most_Common_byMonth:\n",
    "                            Most_Common_byMonth[Place_name]['Total'] += 1\n",
    "                        else:\n",
    "                            Most_Common_byMonth[Place_name]= {}\n",
    "                        \n",
    "                       \n",
    "                     \n",
    "                            Most_Common_byMonth[Place_name]['Total'] = 1\n",
    "                            Most_Common_byMonth[Place_name]['ID'] = Place_ID\n",
    "                        \n",
    "          \n",
    "            \n",
    "\n",
    "                    \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Most_Common_df_month = pd.DataFrame(Most_Common_byMonth)\n",
    "\n",
    "Most_Common_df_month= Most_Common_df_month.T\n",
    "Most_Common_df_month.sort_values('Total', ascending=False, inplace=True)\n",
    "Most_Common_df_month.to_csv('Most_Common_byMonth.csv')\n",
    "Most_Common_df_month.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe and add a 'Total' row which sums up the migrants in CO per month\n",
    "\n",
    "Months_df_ByMonth_no_recurrent = pd.DataFrame(Months_Dicts_byMonth_no_recurrent)\n",
    "Months_df_ByMonth_no_recurrent = Months_df_ByMonth_no_recurrent.T\n",
    "Months_df_ByMonth_no_recurrent.loc['Total'] = Months_df_ByMonth_no_recurrent.sum(axis=0)\n",
    "\n",
    "\n",
    "Months_df_ByMonth_no_recurrent.to_csv('Months_df_ByMonth_no_recurrent.csv')\n",
    "\n",
    "\n",
    "# Select time periods to analyze\n",
    "\n",
    "months_df_month_22_no_recurrent = Months_df_ByMonth_no_recurrent.drop(columns=Months_df_ByMonth_no_recurrent.columns[:48], axis=1)\n",
    "months_df_feb_22_no_recurrent = months_df_month_22_no_recurrent[['2022_02']]\n",
    "Jan_to_March_df_22_no_recurrent = Months_df_ByMonth_no_recurrent.iloc[:, 48:51]\n",
    "\n",
    "\n",
    "# Add column with average value per city over the time period selected: Excluding recurrent\n",
    "\n",
    "months_df_month_22_no_recurrent['Mean'] = months_df_month_22_no_recurrent.mean(axis=1)\n",
    "months_df_feb_22_no_recurrent['Mean'] =months_df_feb_22_no_recurrent.mean(axis=1)\n",
    "Jan_to_March_df_22_no_recurrent['Mean'] =Jan_to_March_df_22_no_recurrent.mean(axis=1)\n",
    "\n",
    "# Sort values: Excluding recurrent\n",
    "Cities_top_feb_no_recurrent = months_df_feb_22_no_recurrent.sort_values('Mean', ascending=False).head(20)\n",
    "Cities_top_22_no_recurrent = months_df_month_22_no_recurrent.sort_values('Mean', ascending=False).head(10)\n",
    "Cities_top_Jan_to_March_no_recurrent = Jan_to_March_df_22_no_recurrent.sort_values('Mean', ascending=False).head(10)\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "Result_df_city_migrants_upscaled_month_feb_no_recurrent = pd.DataFrame(2477588/Cities_top_feb_no_recurrent.at['Total', 'Mean'] * Cities_top_feb_no_recurrent['Mean'])\n",
    "\n",
    "Result_df_city_migrants_upscaled_month_JanMarch_no_reccurent = pd.DataFrame(2477588/Cities_top_Jan_to_March_no_recurrent.at['Total', 'Mean'] * Cities_top_Jan_to_March_no_recurrent['Mean'])\n",
    "\n",
    "Result_df_city_migrants_upscaled_month_22_no_recurrent = pd.DataFrame(2477588/Cities_top_22_no_recurrent.at['Total', 'Mean'] * Cities_top_22_no_recurrent['Mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cities_top_feb_no_recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratio_feb_Bogota_month =  495236/31\n",
    "Ratio_feb_Barranquilla_month = official_Barranquilla_22/1\n",
    "Ratio_feb_Cucuta_month = 167678/5\n",
    "Ratio_feb_Medellin_month = 190854/13\n",
    "Ratio_feb_Candelaria_month = 121837/4\n",
    "new_Ratios_feb_month_no_recurrent = [Ratio_feb_Bogota_month, Ratio_feb_Candelaria_month, Ratio_feb_Barranquilla_month, Ratio_feb_Cucuta_month, Ratio_feb_Medellin_month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.25277625739226"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(new_Ratios_feb_month_no_recurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_df_city_migrants_upscaled_month_feb_no_recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Transpose the DataFrame to have inner dictionaries as rows\n",
    "new_df = Months_df_month.T\n",
    "\n",
    "# Plotting the DataFrame\n",
    "\n",
    "ax = new_df.plot.line()\n",
    "\n",
    "# Move the legend to the right side\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_title('Migrants in Colombian cities: \\n Sliding window without recurring migrants')\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each non-recurrent migrant, find the Colombian city in which they last were detected to be resident and check if afterwards they returned to Venezuela or not\n",
    "\n",
    "timezone = pytz.timezone('UTC')\n",
    "now = dt.datetime.now(timezone)\n",
    "\n",
    "# The three categories\n",
    "Moved_on = []\n",
    "Returned_month = []\n",
    "Not_Returned_month = []\n",
    "\n",
    "\n",
    "Last_Residence_dict_month ={}\n",
    "\n",
    "\n",
    "\n",
    "for u in CO_Residents:\n",
    "    if u not in recurrent_bymonth:\n",
    "  \n",
    "        User_df = Residents[Residents.user == u].copy()\n",
    "\n",
    "        VE = User_df[User_df.country == 'VE']\n",
    "        CO = User_df[User_df.country == 'CO']\n",
    "        Other = User_df[User_df.country == 'other']\n",
    "        sequences_CO = CO.iloc[:,3:].apply(lambda row: get_sequences(row), axis=1)\n",
    "        sequences_VE = VE.iloc[:,3:].apply(lambda row: get_sequences(row), axis=1)\n",
    "        sequences_other = Other.iloc[:,3:].apply(lambda row: get_sequences(row), axis=1)\n",
    "        for index, row_sequences in sequences_CO.items():\n",
    "            if len(row_sequences) > 0:\n",
    "                last_sequence = row_sequences[-1]\n",
    "                start, end = last_sequence\n",
    "                    \n",
    "            \n",
    "                year_str, month_str = start.split('_')\n",
    "                year_int = int(year_str)\n",
    "                month_int = int(month_str)\n",
    "\n",
    "                year_int = int(year_str)\n",
    "                month_int = int(month_str)\n",
    "                period_start_CO = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                year_str, month_str = end.split('_')\n",
    "                year_int = int(year_str)\n",
    "                month_int = int(month_str)\n",
    "\n",
    "\n",
    "                period_end = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                period_end = period_end.replace(day=28) + dt.timedelta(days=4)\n",
    "                period_end_CO = period_end - dt.timedelta(days=period_end.day)\n",
    "                Tweet_df = All_tweets[All_tweets.User_ID == u].copy()\n",
    "                Tweet_df_in_residence_period = Tweet_df[(Tweet_df['Created_At'] >= period_start_CO) & (Tweet_df['Created_At'] <= period_end_CO) & (Tweet_df['Place'] == 'CO')].copy()\n",
    "                valid_row = {}                          \n",
    "                Tweet_df_in_residence_period.apply(process_tweet, axis=1, args=(valid_row,))\n",
    "\n",
    "                \n",
    "            # Find the dictionary with the highest Occurence value in valid_row\n",
    "                Max_Duration = max(valid_row.values(), key=lambda x: x['Occurence'])\n",
    "                Full_name = Max_Duration['Full_name']\n",
    "                Exact_Loc = Max_Duration\n",
    "                for index, row_sequences in sequences_other.items():\n",
    "                    if len(row_sequences) > 0:\n",
    "                        last_sequence = row_sequences[-1]\n",
    "                        start, end = last_sequence\n",
    "                        \n",
    "                        year_str, month_str = start.split('_')\n",
    "                        year_int = int(year_str)\n",
    "                        month_int = int(month_str)\n",
    "\n",
    "                        year_int = int(year_str)\n",
    "                        month_int = int(month_str)\n",
    "                        period_start_other = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "                        if period_start_other>period_start_CO:\n",
    "\n",
    "                            Moved_on.append(u)\n",
    "\n",
    "        \n",
    "        for index, row_sequences in sequences_VE.items():\n",
    "            if len(row_sequences) > 0:\n",
    "                last_sequence = row_sequences[-1]\n",
    "                start, end = last_sequence\n",
    "                    \n",
    "            \n",
    "                year_str, month_str = start.split('_')\n",
    "                year_int = int(year_str)\n",
    "                month_int = int(month_str)\n",
    "\n",
    "                year_int = int(year_str)\n",
    "                month_int = int(month_str)\n",
    "                period_start_VE = dt.datetime(year_int, month_int, 1, tzinfo=timezone)\n",
    "            Diff = (period_end_CO-period_start_CO)              \n",
    "                    \n",
    "     \n",
    "            if Full_name not in Last_Residence_dict_month:\n",
    "                Last_Residence_dict_month[Full_name] = {}\n",
    "                Last_Residence_dict_month[Full_name]['Returned_2022'] = 0\n",
    "                Last_Residence_dict_month[Full_name]['Not_Returned_2022'] = 0\n",
    "                Last_Residence_dict_month[Full_name]['Not_Returned'] = 0\n",
    "                Last_Residence_dict_month[Full_name]['Returned'] = 0\n",
    "                Last_Residence_dict_month[Full_name]['Residents_Time_Not_Returned'] = period_end_CO-period_end_CO\n",
    "                Last_Residence_dict_month[Full_name]['Residents_Time_Returned'] = period_end_CO-period_end_CO\n",
    "            if period_start_CO > period_start_VE:\n",
    "                \n",
    "                Last_Residence_dict_month[Full_name]['Residents_Time_Not_Returned'] += Diff\n",
    "                Last_Residence_dict_month[Full_name]['Not_Returned'] += 1\n",
    "                Not_Returned_month.append(u)\n",
    "                if period_end_CO.year == 2022:\n",
    "                    Last_Residence_dict_month[Full_name]['Not_Returned_2022'] +=1\n",
    "            else: \n",
    "                Last_Residence_dict_month[Full_name]['Returned'] += 1\n",
    "                Last_Residence_dict_month[Full_name]['Residents_Time_Returned'] += Diff\n",
    "                Returned_month.append(u)\n",
    "                if period_start_VE.year == 2022:\n",
    "                    Last_Residence_dict_month[Full_name]['Returned_2022'] +=1\n",
    "                    \n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n",
      "109\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Returned_month))\n",
    "print(len(Not_Returned_month))\n",
    "print(len(Moved_on))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_resident_city_month= pd.DataFrame(Last_Residence_dict_month).T\n",
    "last_resident_city_month['total'] = last_resident_city_month['Not_Returned'] + last_resident_city_month['Returned']\n",
    "\n",
    "last_resident_city_month.sort_values('total', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "last_resident_city_month.replace(0, np.nan, inplace=True)\n",
    "last_resident_city_month['Residents_Time_Not_Returned_Average'] = (last_resident_city_month['Residents_Time_Not_Returned']/ last_resident_city_month['Not_Returned'])\n",
    "last_resident_city_month['Residents_Time_Returned_Average'] = last_resident_city_month['Residents_Time_Returned']/ (last_resident_city_month['Returned'])\n",
    "last_resident_city_month.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_resident_city_month_ratio = last_resident_city_month.drop(columns=last_resident_city_month.columns[4:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_resident_city_month_ratio['Ratio'] = last_resident_city_month_ratio['Returned']/last_resident_city_month_ratio['Not_Returned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_resident_city_month_ratio['Ratio_22'] = last_resident_city_month_ratio['Returned_2022']/last_resident_city_month_ratio['Not_Returned_2022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_resident_city_month_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "Returned_month=[str(i) for i in Returned_month]\n",
    "Not_Returned_month=[str(i) for i in Not_Returned_month]\n",
    "Moved_on = [str(i) for i in Moved_on]\n",
    "recurrent_bymonth = [str(i) for i in recurrent_bymonth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transpose the DataFrame to have inner dictionaries as rows\n",
    "new_df = Months_df_month.T\n",
    "\n",
    "# Plotting the DataFrame\n",
    "\n",
    "ax = new_df.plot.line()\n",
    "\n",
    "# Move the legend to the right side\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_title('Migrants in Colombian cities: \\n Individual month with recurrent migrants')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Number of migrants')\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transpose the DataFrame to have inner dictionaries as rows\n",
    "new_df = Months_df_ByMonth_no_recurrent.T\n",
    "\n",
    "# Plotting the DataFrame\n",
    "\n",
    "ax = new_df.plot.line()\n",
    "\n",
    "# Move the legend to the right side\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_title('Migrants in Colombian cities: \\n Individual month without recurrent migrants')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Number of migrants')\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for a ll returned migrants where their time of residence in Colombia us summed up. the diffrent places they stayed and the number of Colombian residence periods can be found in the Twitter data\n",
    "\n",
    "Returned_dict_month =  {}\n",
    "\n",
    "\n",
    "for k, v in Migrant_dict.items():\n",
    "    if k in Returned_month:\n",
    "        Returned_dict_month[k] = {}\n",
    "        Number_of_res_periods = (len(v)-2)\n",
    "        Duration = v['Entire_Residence_Period_CO']\n",
    "        dict_view = v.items()\n",
    "        IDs = set()\n",
    "        for key, value in itertools.islice(dict_view, 2, None):\n",
    "            print(value)\n",
    "            Place_ID = value['Place_ID']\n",
    "            IDs.add(Place_ID)\n",
    "\n",
    "\n",
    "\n",
    "        Returned_dict_month[k]['Periods'] = Number_of_res_periods\n",
    "        Returned_dict_month[k]['Different_Places'] = len(IDs)\n",
    "        Returned_dict_month[k]['Duration'] = Duration\n",
    "           \n",
    "\n",
    "Returned_df_month = pd.DataFrame(Returned_dict_month).T\n",
    "Returned_df_month.sort_values('Periods', ascending=False, inplace=True)\n",
    "Returned_df_month.to_csv('Returned_df_month.csv')\n",
    "\n",
    "\n",
    "Not_returned_dict_month =  {}\n",
    "for k, v in Migrant_dict.items():\n",
    "    if k in Not_Returned_month:\n",
    "        if k not in Moved_on:\n",
    "            Not_returned_dict_month[k] = {}\n",
    "           \n",
    "            Number_of_res_periods = (len(v)-2)\n",
    "            Duration = v['Entire_Residence_Period_CO']\n",
    "            dict_view = v.items()\n",
    "            IDs = set()\n",
    "            for key, value in itertools.islice(dict_view, 2, None):\n",
    "                Place_ID = value['Place_ID']\n",
    "                IDs.add(Place_ID)\n",
    "\n",
    "\n",
    "\n",
    "            Not_returned_dict_month[k]['Periods'] = Number_of_res_periods\n",
    "            Not_returned_dict_month[k]['Different_Places'] = len(IDs)\n",
    "            Not_returned_dict_month[k]['Duration'] = Duration\n",
    "           \n",
    "Not_returned_df_month = pd.DataFrame(Not_returned_dict_month).T\n",
    "Not_returned_df_month.sort_values('Periods', ascending=False, inplace=True)\n",
    "Not_returned_df_month.to_csv('Not_returned_dict_month.csv')\n",
    "Not_returned_df_month.head(10)\n",
    "\n",
    "Recurrent_dict_month =  {}\n",
    "for k, v in Migrant_dict.items():\n",
    "    IDs = set()\n",
    "    if k in recurrent_bymonth:\n",
    "\n",
    "        Recurrent_dict_month[k] = {}\n",
    "        Number_of_res_periods = (len(v)-2)\n",
    "        Duration = v['Entire_Residence_Period_CO']\n",
    "        dict_view = v.items()\n",
    "        print(dict_view)\n",
    "        for key, value in itertools.islice(dict_view, 2, None):\n",
    "            print(value)\n",
    "            \n",
    "            Place_ID = value['Place_ID']\n",
    "            print(Place_ID)\n",
    "            IDs.add(Place_ID)\n",
    "        print(len(IDs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Recurrent_dict_month[k]['Periods'] = Number_of_res_periods\n",
    "        Recurrent_dict_month[k]['Different_Places'] = len(IDs)\n",
    "        Recurrent_dict_month[k]['Duration'] = Duration\n",
    "           \n",
    "Recurrent_df_month = pd.DataFrame(Recurrent_dict_month).T\n",
    "Recurrent_df_month.sort_values('Periods', ascending=False, inplace=True)\n",
    "Recurrent_df_month.to_csv('Recurrent_df_month.csv')\n",
    "Recurrent_df_month.head(10)\n",
    "\n",
    "\n",
    "Average_periods_returned = Returned_df_month['Periods'].sum()/len(Returned_df_month)\n",
    "Average_places_returned = Returned_df_month['Different_Places'].sum()/len(Returned_df_month)\n",
    "Average_duration_returned = Returned_df_month['Duration'].dt.days.sum()/len(Returned_df_month)\n",
    "Average_periods_returned = Returned_df_month['Periods'].sum()/len(Returned_df_month)\n",
    "\n",
    "Average_periods_not_returned = Not_returned_df_month['Periods'].sum()/len(Not_returned_df_month)\n",
    "Average_places_not_returned = Not_returned_df_month['Different_Places'].sum()/len(Not_returned_df_month)\n",
    "Average_duration_not_returned = Not_returned_df_month['Duration'].dt.days.sum()/len(Not_returned_df_month)\n",
    "Average_periods_not_returned = Not_returned_df_month['Periods'].sum()/len(Not_returned_df_month)\n",
    "\n",
    "\n",
    "Average_periods_recurrent = Recurrent_df_month['Periods'].sum()/len(Recurrent_df_month)\n",
    "Average_places_recurrent = Recurrent_df_month['Different_Places'].sum()/len(Recurrent_df_month)\n",
    "Average_duration_recurrent = Recurrent_df_month['Duration'].dt.days.sum()/len(Recurrent_df_month)\n",
    "Average_periods_recurrent = Recurrent_df_month['Periods'].sum()/len(Recurrent_df_month)\n",
    "\n",
    "Average_dict = {}\n",
    "Average_dict['Average_duration_not_returned'] = Average_duration_not_returned\n",
    "Average_dict['Average_duration_returned'] = Average_duration_returned\n",
    "Average_dict['Average_duration__recurrent'] = Average_duration_recurrent\n",
    "Average_dict['Average_places_not_returned'] = Average_places_not_returned\n",
    "Average_dict['Average_places_recurrent'] = Average_places_recurrent\n",
    "Average_dict['Average_places_returned'] = Average_places_returned\n",
    "Average_dict['Average_periods_not_returned'] = Average_periods_not_returned\n",
    "Average_dict['Average_periods_returned'] = Average_periods_returned\n",
    "Average_dict['Average_periods_recurrent'] = Average_periods_recurrent\n",
    "\n",
    "Average_df = pd.DataFrame(Average_dict, index=(Average_dict.values()))\n",
    "Average_df = Average_df.T\n",
    "\n",
    "Average_df.rename(columns={346.400685: 'Average'},  inplace=True)\n",
    "Average_df.drop(columns=Average_df.columns[1:], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Average_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
